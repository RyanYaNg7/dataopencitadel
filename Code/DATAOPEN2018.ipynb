{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemicals = pd.read_csv(\"chemicals.csv\")\n",
    "earnings = pd.read_csv(\"earnings.csv\", encoding = \"ISO-8859-1\")\n",
    "industry_occupation = pd.read_csv(\"industry_occupation.csv\", encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_score = pd.read_csv(\"chem_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemicals[\"fips\"] = chemicals['fips'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "chemicals.fips.apply(str)\n",
    "earnings['fips'] = earnings['fips'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "earnings.fips.apply(str)\n",
    "industry_occupation[\"fips\"] = industry_occupation['fips'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "industry_occupation.fips.apply(str)\n",
    "earnings.to_csv(\"earnings_updated_fips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in industry_occupation.columns[4:len(industry_occupation.columns) - 1]:\n",
    "    industry_occupation[col] /= industry_occupation.total_employed\n",
    "for col in industry_occupation.columns[4:len(industry_occupation.columns) - 1]:\n",
    "    industry_occupation[col] = industry_occupation[col].fillna(industry_occupation.groupby('year')[col].transform(\"mean\"))\n",
    "industry_occupation.to_csv(\"industry_updated_fips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation = industry_occupation.drop(\"total_employed\", 1)\n",
    "industry_occupation_lag = industry_occupation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation['year'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation.year = industry_occupation.year.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation[\"new_index\"] = industry_occupation.year + industry_occupation.geo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation_lag.year = industry_occupation_lag.year.apply(str)\n",
    "industry_occupation_lag['new_index'] = industry_occupation_lag.year + industry_occupation_lag.geo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation = industry_occupation.set_index(['new_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation_lag = industry_occupation_lag.set_index(['new_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = [industry_occupation_lag.columns[i] + '_1' for i in range(len(industry_occupation_lag.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_occupation_lag.columns = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([industry_occupation, industry_occupation_lag], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.reset_index()\n",
    "result = result.drop(['geo_id_1', 'fips_1', 'county_1', 'year_1', 'new_index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Industry_lag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## earnings \n",
    "\n",
    "normalized_earnings = pd.read_csv(\"normalized_earnings.csv\")\n",
    "normalized_earnings.year = normalized_earnings.year.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_earnings_lag = normalized_earnings.copy()\n",
    "normalized_earnings.year += 1\n",
    "normalized_earnings.year = normalized_earnings.year.apply(str)\n",
    "normalized_earnings.fips = normalized_earnings.fips.apply(str)\n",
    "normalized_earnings[\"new_index\"] = normalized_earnings.year + normalized_earnings.fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_earnings_lag.year = normalized_earnings_lag.year.apply(str)\n",
    "normalized_earnings_lag.fips = normalized_earnings_lag.fips.apply(str)\n",
    "normalized_earnings_lag[\"new_index\"] = normalized_earnings_lag.year + normalized_earnings_lag.fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_earnings = normalized_earnings.set_index(['new_index'])\n",
    "normalized_earnings_lag = normalized_earnings_lag.set_index(['new_index'])\n",
    "new_col = [normalized_earnings_lag.columns[i] + '_1' for i in range(len(normalized_earnings_lag.columns))]\n",
    "normalized_earnings_lag.columns = new_col\n",
    "result2 = pd.concat([normalized_earnings, normalized_earnings_lag], axis = 1, join = \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result2.reset_index()\n",
    "result2 = result2.drop(['new_index', 'year_1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(\"normalized_earnings_lag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_agri_fish_mine</th>\n",
       "      <th>agri_fish_hunt</th>\n",
       "      <th>mining_quarrying_oilgas_extract</th>\n",
       "      <th>construction</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>wholesale_trade</th>\n",
       "      <th>retail_trade</th>\n",
       "      <th>transport_warehouse_utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>mgmt_1</th>\n",
       "      <th>admin_sup_1</th>\n",
       "      <th>total_edu_health_social_1</th>\n",
       "      <th>edu_serv_1</th>\n",
       "      <th>health_social_1</th>\n",
       "      <th>total_arts_ent_acc_food_1</th>\n",
       "      <th>arts_ent_rec_1</th>\n",
       "      <th>acc_food_serv_1</th>\n",
       "      <th>other_ser_1</th>\n",
       "      <th>pub_admin_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>0.035264</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.032354</td>\n",
       "      <td>0.060475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.093891</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.049803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027452</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.029922</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>0.043733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.026422</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.045156</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.068945</td>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>0.052426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.043590</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.043170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088554</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.019591</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.041305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.031778</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.039811</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.026629</td>\n",
       "      <td>0.056206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.038854</td>\n",
       "      <td>0.047215</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.029518</td>\n",
       "      <td>0.044929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  fips  total_agri_fish_mine  agri_fish_hunt  \\\n",
       "0      0  1001              0.038453        0.038651   \n",
       "1      1  1003              0.038482        0.031718   \n",
       "2      2  1005              0.026422        0.023638   \n",
       "3      3  1007              0.054425        0.055420   \n",
       "4      4  1009              0.033389        0.031778   \n",
       "\n",
       "   mining_quarrying_oilgas_extract  construction  manufacturing  \\\n",
       "0                         0.027040      0.036704       0.053763   \n",
       "1                         0.093891      0.034880       0.048625   \n",
       "2                         0.044943      0.033184       0.045156   \n",
       "3                         0.041394      0.036440       0.043590   \n",
       "4                         0.067470      0.041016       0.039811   \n",
       "\n",
       "   wholesale_trade  retail_trade  transport_warehouse_utilities     ...       \\\n",
       "0         0.046205      0.024608                       0.061353     ...        \n",
       "1         0.050396      0.024145                       0.049803     ...        \n",
       "2         0.030687      0.031284                       0.053479     ...        \n",
       "3         0.052219      0.021749                       0.043170     ...        \n",
       "4         0.041193      0.026629                       0.056206     ...        \n",
       "\n",
       "     mgmt_1  admin_sup_1  total_edu_health_social_1  edu_serv_1  \\\n",
       "0  0.000000     0.034921                   0.037950    0.042534   \n",
       "1  0.000000     0.027452                   0.039780    0.044267   \n",
       "2  0.000000     0.019501                   0.036902    0.068945   \n",
       "3  0.088554     0.032778                   0.034044    0.046197   \n",
       "4  0.000000     0.033605                   0.038854    0.047215   \n",
       "\n",
       "   health_social_1  total_arts_ent_acc_food_1  arts_ent_rec_1  \\\n",
       "0         0.035264                   0.012536        0.013112   \n",
       "1         0.036876                   0.016616        0.029922   \n",
       "2         0.029141                   0.011919        0.013113   \n",
       "3         0.028691                   0.019591        0.004708   \n",
       "4         0.037251                   0.008756        0.007591   \n",
       "\n",
       "   acc_food_serv_1  other_ser_1  pub_admin_1  \n",
       "0         0.012443     0.032354     0.060475  \n",
       "1         0.015958     0.024313     0.043733  \n",
       "2         0.011421     0.025411     0.052426  \n",
       "3         0.022744     0.027503     0.041305  \n",
       "4         0.008822     0.029518     0.044929  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"Industry_lag.csv\")\n",
    "result2 = pd.read_csv(\"normalized_earnings_lag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4884"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18853"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2['fips'] = result2['fips'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "result2['year'] = result2['year'].apply(str)\n",
    "result['fips'] = result['fips'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "result['year'] = result['year'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['new_index'] = result.year+result['fips']\n",
    "result2['new_index'] = result2.year + result2.fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result2.set_index(['new_index'])\n",
    "result = result.set_index(['new_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>fips</th>\n",
       "      <th>county</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>construction</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>wholesale_trade</th>\n",
       "      <th>retail_trade</th>\n",
       "      <th>transport_utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>wholesale_trade_1</th>\n",
       "      <th>retail_trade_1</th>\n",
       "      <th>transport_utilities_1</th>\n",
       "      <th>information_1</th>\n",
       "      <th>finance_insurance_realestate_1</th>\n",
       "      <th>prof_scientific_waste_1</th>\n",
       "      <th>edu_health_1</th>\n",
       "      <th>arts_recreation_1</th>\n",
       "      <th>other_1</th>\n",
       "      <th>public_admin_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101003</th>\n",
       "      <td>0</td>\n",
       "      <td>0500000US01003</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>0.016852</td>\n",
       "      <td>0.083986</td>\n",
       "      <td>0.079391</td>\n",
       "      <td>0.027581</td>\n",
       "      <td>0.123280</td>\n",
       "      <td>0.046038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>0.143542</td>\n",
       "      <td>0.050436</td>\n",
       "      <td>0.014955</td>\n",
       "      <td>0.059526</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.221214</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.048301</td>\n",
       "      <td>0.036560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101015</th>\n",
       "      <td>1</td>\n",
       "      <td>0500000US01015</td>\n",
       "      <td>01015</td>\n",
       "      <td>Calhoun County, Alabama</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>0.183969</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.133418</td>\n",
       "      <td>0.038019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.117222</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.097882</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.081013</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101043</th>\n",
       "      <td>2</td>\n",
       "      <td>0500000US01043</td>\n",
       "      <td>01043</td>\n",
       "      <td>Cullman County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101049</th>\n",
       "      <td>3</td>\n",
       "      <td>0500000US01049</td>\n",
       "      <td>01049</td>\n",
       "      <td>DeKalb County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.135833</td>\n",
       "      <td>0.054265</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>0.080747</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101051</th>\n",
       "      <td>4</td>\n",
       "      <td>0500000US01051</td>\n",
       "      <td>01051</td>\n",
       "      <td>Elmore County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101055</th>\n",
       "      <td>5</td>\n",
       "      <td>0500000US01055</td>\n",
       "      <td>01055</td>\n",
       "      <td>Etowah County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>0.113706</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.045908</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>0.113808</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>0.062973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101069</th>\n",
       "      <td>6</td>\n",
       "      <td>0500000US01069</td>\n",
       "      <td>01069</td>\n",
       "      <td>Houston County, Alabama</td>\n",
       "      <td>0.017374</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.093182</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.136903</td>\n",
       "      <td>0.062415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044390</td>\n",
       "      <td>0.119499</td>\n",
       "      <td>0.096198</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.038269</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.225213</td>\n",
       "      <td>0.090322</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.051472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101073</th>\n",
       "      <td>7</td>\n",
       "      <td>0500000US01073</td>\n",
       "      <td>01073</td>\n",
       "      <td>Jefferson County, Alabama</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.061087</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.030606</td>\n",
       "      <td>0.117545</td>\n",
       "      <td>0.050879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>0.101286</td>\n",
       "      <td>0.053590</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>0.116549</td>\n",
       "      <td>0.272641</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.044486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101077</th>\n",
       "      <td>8</td>\n",
       "      <td>0500000US01077</td>\n",
       "      <td>01077</td>\n",
       "      <td>Lauderdale County, Alabama</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.090422</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.034461</td>\n",
       "      <td>0.152775</td>\n",
       "      <td>0.062505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101081</th>\n",
       "      <td>9</td>\n",
       "      <td>0500000US01081</td>\n",
       "      <td>01081</td>\n",
       "      <td>Lee County, Alabama</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.052026</td>\n",
       "      <td>0.120861</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.128486</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.040722</td>\n",
       "      <td>0.076828</td>\n",
       "      <td>0.288127</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.039910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101083</th>\n",
       "      <td>10</td>\n",
       "      <td>0500000US01083</td>\n",
       "      <td>01083</td>\n",
       "      <td>Limestone County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101089</th>\n",
       "      <td>11</td>\n",
       "      <td>0500000US01089</td>\n",
       "      <td>01089</td>\n",
       "      <td>Madison County, Alabama</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.117735</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.096425</td>\n",
       "      <td>0.029486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.117546</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>0.179244</td>\n",
       "      <td>0.081932</td>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.087763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101095</th>\n",
       "      <td>12</td>\n",
       "      <td>0500000US01095</td>\n",
       "      <td>01095</td>\n",
       "      <td>Marshall County, Alabama</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.098027</td>\n",
       "      <td>0.217227</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.133881</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>0.114291</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.036929</td>\n",
       "      <td>0.062762</td>\n",
       "      <td>0.198167</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.043829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101097</th>\n",
       "      <td>13</td>\n",
       "      <td>0500000US01097</td>\n",
       "      <td>01097</td>\n",
       "      <td>Mobile County, Alabama</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.123341</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.132165</td>\n",
       "      <td>0.054505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>0.139225</td>\n",
       "      <td>0.054112</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.056813</td>\n",
       "      <td>0.097774</td>\n",
       "      <td>0.233898</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>0.059638</td>\n",
       "      <td>0.039582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101101</th>\n",
       "      <td>14</td>\n",
       "      <td>0500000US01101</td>\n",
       "      <td>01101</td>\n",
       "      <td>Montgomery County, Alabama</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>0.120144</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.216640</td>\n",
       "      <td>0.102690</td>\n",
       "      <td>0.057959</td>\n",
       "      <td>0.119482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101103</th>\n",
       "      <td>15</td>\n",
       "      <td>0500000US01103</td>\n",
       "      <td>01103</td>\n",
       "      <td>Morgan County, Alabama</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.213297</td>\n",
       "      <td>0.031806</td>\n",
       "      <td>0.103293</td>\n",
       "      <td>0.061675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.125086</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>0.075295</td>\n",
       "      <td>0.059207</td>\n",
       "      <td>0.033121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101115</th>\n",
       "      <td>16</td>\n",
       "      <td>0500000US01115</td>\n",
       "      <td>01115</td>\n",
       "      <td>St. Clair County, Alabama</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>0.080631</td>\n",
       "      <td>0.126615</td>\n",
       "      <td>0.057098</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.061154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101117</th>\n",
       "      <td>17</td>\n",
       "      <td>0500000US01117</td>\n",
       "      <td>01117</td>\n",
       "      <td>Shelby County, Alabama</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.077871</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>0.037660</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.114391</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>0.197602</td>\n",
       "      <td>0.061784</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>0.046985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101121</th>\n",
       "      <td>18</td>\n",
       "      <td>0500000US01121</td>\n",
       "      <td>01121</td>\n",
       "      <td>Talladega County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101125</th>\n",
       "      <td>19</td>\n",
       "      <td>0500000US01125</td>\n",
       "      <td>01125</td>\n",
       "      <td>Tuscaloosa County, Alabama</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.089644</td>\n",
       "      <td>0.108741</td>\n",
       "      <td>0.022671</td>\n",
       "      <td>0.115294</td>\n",
       "      <td>0.035811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.034689</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.054224</td>\n",
       "      <td>0.067698</td>\n",
       "      <td>0.284911</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.042211</td>\n",
       "      <td>0.048357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101127</th>\n",
       "      <td>20</td>\n",
       "      <td>0500000US01127</td>\n",
       "      <td>01127</td>\n",
       "      <td>Walker County, Alabama</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102020</th>\n",
       "      <td>21</td>\n",
       "      <td>0500000US02020</td>\n",
       "      <td>02020</td>\n",
       "      <td>Anchorage Municipality, Alaska</td>\n",
       "      <td>0.027366</td>\n",
       "      <td>0.057360</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.119391</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030751</td>\n",
       "      <td>0.117070</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.110399</td>\n",
       "      <td>0.249707</td>\n",
       "      <td>0.100512</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.111625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102090</th>\n",
       "      <td>22</td>\n",
       "      <td>0500000US02090</td>\n",
       "      <td>02090</td>\n",
       "      <td>Fairbanks North Star Borough, Alaska</td>\n",
       "      <td>0.052167</td>\n",
       "      <td>0.099509</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>0.031503</td>\n",
       "      <td>0.096909</td>\n",
       "      <td>0.061595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.142124</td>\n",
       "      <td>0.072324</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.217588</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>0.049263</td>\n",
       "      <td>0.150334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102170</th>\n",
       "      <td>23</td>\n",
       "      <td>0500000US02170</td>\n",
       "      <td>02170</td>\n",
       "      <td>Matanuska-Susitna Borough, Alaska</td>\n",
       "      <td>0.069939</td>\n",
       "      <td>0.112447</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.119858</td>\n",
       "      <td>0.052798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.107263</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.020109</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.251476</td>\n",
       "      <td>0.078537</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>0.083070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104001</th>\n",
       "      <td>24</td>\n",
       "      <td>0500000US04001</td>\n",
       "      <td>04001</td>\n",
       "      <td>Apache County, Arizona</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104003</th>\n",
       "      <td>25</td>\n",
       "      <td>0500000US04003</td>\n",
       "      <td>04003</td>\n",
       "      <td>Cochise County, Arizona</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.056097</td>\n",
       "      <td>0.023664</td>\n",
       "      <td>0.037363</td>\n",
       "      <td>0.101816</td>\n",
       "      <td>0.052754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104005</th>\n",
       "      <td>26</td>\n",
       "      <td>0500000US04005</td>\n",
       "      <td>04005</td>\n",
       "      <td>Coconino County, Arizona</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.061902</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.129436</td>\n",
       "      <td>0.057329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.126760</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>0.071978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104013</th>\n",
       "      <td>27</td>\n",
       "      <td>0500000US04013</td>\n",
       "      <td>04013</td>\n",
       "      <td>Maricopa County, Arizona</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.066253</td>\n",
       "      <td>0.081239</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.125761</td>\n",
       "      <td>0.052707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.120632</td>\n",
       "      <td>0.051141</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.099774</td>\n",
       "      <td>0.130022</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.046061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104015</th>\n",
       "      <td>28</td>\n",
       "      <td>0500000US04015</td>\n",
       "      <td>04015</td>\n",
       "      <td>Mohave County, Arizona</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>0.077106</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>0.156779</td>\n",
       "      <td>0.059489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.130677</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>0.052163</td>\n",
       "      <td>0.076398</td>\n",
       "      <td>0.189562</td>\n",
       "      <td>0.174207</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104017</th>\n",
       "      <td>29</td>\n",
       "      <td>0500000US04017</td>\n",
       "      <td>04017</td>\n",
       "      <td>Navajo County, Arizona</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.063626</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.121484</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654033</th>\n",
       "      <td>4854</td>\n",
       "      <td>0500000US54033</td>\n",
       "      <td>54033</td>\n",
       "      <td>Harrison County, West Virginia</td>\n",
       "      <td>0.052257</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.039520</td>\n",
       "      <td>0.143044</td>\n",
       "      <td>0.079076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.118177</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.296526</td>\n",
       "      <td>0.085022</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>0.115786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654039</th>\n",
       "      <td>4855</td>\n",
       "      <td>0500000US54039</td>\n",
       "      <td>54039</td>\n",
       "      <td>Kanawha County, West Virginia</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.046901</td>\n",
       "      <td>0.043511</td>\n",
       "      <td>0.020314</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>0.042439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.079815</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.065889</td>\n",
       "      <td>0.100224</td>\n",
       "      <td>0.270667</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654061</th>\n",
       "      <td>4856</td>\n",
       "      <td>0500000US54061</td>\n",
       "      <td>54061</td>\n",
       "      <td>Monongalia County, West Virginia</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.121354</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.059201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654081</th>\n",
       "      <td>4857</td>\n",
       "      <td>0500000US54081</td>\n",
       "      <td>54081</td>\n",
       "      <td>Raleigh County, West Virginia</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025861</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.238304</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.049026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654107</th>\n",
       "      <td>4858</td>\n",
       "      <td>0500000US54107</td>\n",
       "      <td>54107</td>\n",
       "      <td>Wood County, West Virginia</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.077212</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.162409</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.131056</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.320483</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.089474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655009</th>\n",
       "      <td>4859</td>\n",
       "      <td>0500000US55009</td>\n",
       "      <td>55009</td>\n",
       "      <td>Brown County, Wisconsin</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.066020</td>\n",
       "      <td>0.204324</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031923</td>\n",
       "      <td>0.105683</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>0.084382</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>0.093170</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>0.020846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655025</th>\n",
       "      <td>4860</td>\n",
       "      <td>0500000US55025</td>\n",
       "      <td>55025</td>\n",
       "      <td>Dane County, Wisconsin</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.043498</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>0.099005</td>\n",
       "      <td>0.028650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.100363</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.082944</td>\n",
       "      <td>0.137849</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>0.090658</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655027</th>\n",
       "      <td>4861</td>\n",
       "      <td>0500000US55027</td>\n",
       "      <td>55027</td>\n",
       "      <td>Dodge County, Wisconsin</td>\n",
       "      <td>0.047311</td>\n",
       "      <td>0.071880</td>\n",
       "      <td>0.277360</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.109898</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.185140</td>\n",
       "      <td>0.063427</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>0.030040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655035</th>\n",
       "      <td>4862</td>\n",
       "      <td>0500000US55035</td>\n",
       "      <td>55035</td>\n",
       "      <td>Eau Claire County, Wisconsin</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.040975</td>\n",
       "      <td>0.134874</td>\n",
       "      <td>0.025018</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>0.042310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.193205</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.059241</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.267207</td>\n",
       "      <td>0.079175</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.033937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655039</th>\n",
       "      <td>4863</td>\n",
       "      <td>0500000US55039</td>\n",
       "      <td>55039</td>\n",
       "      <td>Fond du Lac County, Wisconsin</td>\n",
       "      <td>0.041512</td>\n",
       "      <td>0.066198</td>\n",
       "      <td>0.209342</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.047177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>0.209634</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.045790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655055</th>\n",
       "      <td>4864</td>\n",
       "      <td>0500000US55055</td>\n",
       "      <td>55055</td>\n",
       "      <td>Jefferson County, Wisconsin</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>0.072253</td>\n",
       "      <td>0.239923</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>0.111838</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.238870</td>\n",
       "      <td>0.077360</td>\n",
       "      <td>0.043771</td>\n",
       "      <td>0.026514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655059</th>\n",
       "      <td>4865</td>\n",
       "      <td>0500000US55059</td>\n",
       "      <td>55059</td>\n",
       "      <td>Kenosha County, Wisconsin</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.054538</td>\n",
       "      <td>0.194387</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.119787</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.169675</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.085926</td>\n",
       "      <td>0.225782</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655063</th>\n",
       "      <td>4866</td>\n",
       "      <td>0500000US55063</td>\n",
       "      <td>55063</td>\n",
       "      <td>La Crosse County, Wisconsin</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.041080</td>\n",
       "      <td>0.117299</td>\n",
       "      <td>0.029420</td>\n",
       "      <td>0.139698</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>0.127378</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.032632</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>0.298961</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.032293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655071</th>\n",
       "      <td>4867</td>\n",
       "      <td>0500000US55071</td>\n",
       "      <td>55071</td>\n",
       "      <td>Manitowoc County, Wisconsin</td>\n",
       "      <td>0.033466</td>\n",
       "      <td>0.056320</td>\n",
       "      <td>0.294886</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.122107</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.092097</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.020994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655073</th>\n",
       "      <td>4868</td>\n",
       "      <td>0500000US55073</td>\n",
       "      <td>55073</td>\n",
       "      <td>Marathon County, Wisconsin</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>0.221681</td>\n",
       "      <td>0.034892</td>\n",
       "      <td>0.118089</td>\n",
       "      <td>0.050850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.109750</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>0.067402</td>\n",
       "      <td>0.227370</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.027045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655079</th>\n",
       "      <td>4869</td>\n",
       "      <td>0500000US55079</td>\n",
       "      <td>55079</td>\n",
       "      <td>Milwaukee County, Wisconsin</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.151928</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.098580</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.110877</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.061934</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.258274</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655087</th>\n",
       "      <td>4870</td>\n",
       "      <td>0500000US55087</td>\n",
       "      <td>55087</td>\n",
       "      <td>Outagamie County, Wisconsin</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.082346</td>\n",
       "      <td>0.215747</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.109190</td>\n",
       "      <td>0.039578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>0.090829</td>\n",
       "      <td>0.207668</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.027592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655089</th>\n",
       "      <td>4871</td>\n",
       "      <td>0500000US55089</td>\n",
       "      <td>55089</td>\n",
       "      <td>Ozaukee County, Wisconsin</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.034342</td>\n",
       "      <td>0.192271</td>\n",
       "      <td>0.034706</td>\n",
       "      <td>0.116056</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.109572</td>\n",
       "      <td>0.037420</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.108895</td>\n",
       "      <td>0.233125</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.033925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655097</th>\n",
       "      <td>4872</td>\n",
       "      <td>0500000US55097</td>\n",
       "      <td>55097</td>\n",
       "      <td>Portage County, Wisconsin</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.045415</td>\n",
       "      <td>0.136377</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.125702</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.027890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655101</th>\n",
       "      <td>4873</td>\n",
       "      <td>0500000US55101</td>\n",
       "      <td>55101</td>\n",
       "      <td>Racine County, Wisconsin</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.058076</td>\n",
       "      <td>0.213810</td>\n",
       "      <td>0.033885</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.055805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>0.086634</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.076496</td>\n",
       "      <td>0.040780</td>\n",
       "      <td>0.032095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655105</th>\n",
       "      <td>4874</td>\n",
       "      <td>0500000US55105</td>\n",
       "      <td>55105</td>\n",
       "      <td>Rock County, Wisconsin</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>0.223351</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>0.129027</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033063</td>\n",
       "      <td>0.115378</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.066037</td>\n",
       "      <td>0.212013</td>\n",
       "      <td>0.071704</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.029149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655109</th>\n",
       "      <td>4875</td>\n",
       "      <td>0500000US55109</td>\n",
       "      <td>55109</td>\n",
       "      <td>St. Croix County, Wisconsin</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.077924</td>\n",
       "      <td>0.187480</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>0.105853</td>\n",
       "      <td>0.059818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>0.023498</td>\n",
       "      <td>0.069111</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>0.070616</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.037007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655117</th>\n",
       "      <td>4876</td>\n",
       "      <td>0500000US55117</td>\n",
       "      <td>55117</td>\n",
       "      <td>Sheboygan County, Wisconsin</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.043523</td>\n",
       "      <td>0.330605</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.113864</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.028649</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.067037</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.185135</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.025314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655127</th>\n",
       "      <td>4877</td>\n",
       "      <td>0500000US55127</td>\n",
       "      <td>55127</td>\n",
       "      <td>Walworth County, Wisconsin</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.098004</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.107505</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>0.134970</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>0.225702</td>\n",
       "      <td>0.106738</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.025108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655131</th>\n",
       "      <td>4878</td>\n",
       "      <td>0500000US55131</td>\n",
       "      <td>55131</td>\n",
       "      <td>Washington County, Wisconsin</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.131752</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.095768</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.015786</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>0.207379</td>\n",
       "      <td>0.075402</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>0.037876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655133</th>\n",
       "      <td>4879</td>\n",
       "      <td>0500000US55133</td>\n",
       "      <td>55133</td>\n",
       "      <td>Waukesha County, Wisconsin</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.051561</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.109892</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042637</td>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.082146</td>\n",
       "      <td>0.110605</td>\n",
       "      <td>0.223792</td>\n",
       "      <td>0.076854</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.027043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655139</th>\n",
       "      <td>4880</td>\n",
       "      <td>0500000US55139</td>\n",
       "      <td>55139</td>\n",
       "      <td>Winnebago County, Wisconsin</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.041022</td>\n",
       "      <td>0.249727</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.123855</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>0.199925</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>0.024915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655141</th>\n",
       "      <td>4881</td>\n",
       "      <td>0500000US55141</td>\n",
       "      <td>55141</td>\n",
       "      <td>Wood County, Wisconsin</td>\n",
       "      <td>0.054501</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.168087</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.128092</td>\n",
       "      <td>0.048241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021737</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.067083</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>0.043448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656021</th>\n",
       "      <td>4882</td>\n",
       "      <td>0500000US56021</td>\n",
       "      <td>56021</td>\n",
       "      <td>Laramie County, Wyoming</td>\n",
       "      <td>0.064778</td>\n",
       "      <td>0.047264</td>\n",
       "      <td>0.044145</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.065061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.061820</td>\n",
       "      <td>0.033988</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.259028</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>0.059652</td>\n",
       "      <td>0.127411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656025</th>\n",
       "      <td>4883</td>\n",
       "      <td>0500000US56025</td>\n",
       "      <td>56025</td>\n",
       "      <td>Natrona County, Wyoming</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.069455</td>\n",
       "      <td>0.055505</td>\n",
       "      <td>0.032460</td>\n",
       "      <td>0.139976</td>\n",
       "      <td>0.042372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.074406</td>\n",
       "      <td>0.262701</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.036316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4884 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0          geo_id   fips  \\\n",
       "new_index                                      \n",
       "201101003           0  0500000US01003  01003   \n",
       "201101015           1  0500000US01015  01015   \n",
       "201101043           2  0500000US01043  01043   \n",
       "201101049           3  0500000US01049  01049   \n",
       "201101051           4  0500000US01051  01051   \n",
       "201101055           5  0500000US01055  01055   \n",
       "201101069           6  0500000US01069  01069   \n",
       "201101073           7  0500000US01073  01073   \n",
       "201101077           8  0500000US01077  01077   \n",
       "201101081           9  0500000US01081  01081   \n",
       "201101083          10  0500000US01083  01083   \n",
       "201101089          11  0500000US01089  01089   \n",
       "201101095          12  0500000US01095  01095   \n",
       "201101097          13  0500000US01097  01097   \n",
       "201101101          14  0500000US01101  01101   \n",
       "201101103          15  0500000US01103  01103   \n",
       "201101115          16  0500000US01115  01115   \n",
       "201101117          17  0500000US01117  01117   \n",
       "201101121          18  0500000US01121  01121   \n",
       "201101125          19  0500000US01125  01125   \n",
       "201101127          20  0500000US01127  01127   \n",
       "201102020          21  0500000US02020  02020   \n",
       "201102090          22  0500000US02090  02090   \n",
       "201102170          23  0500000US02170  02170   \n",
       "201104001          24  0500000US04001  04001   \n",
       "201104003          25  0500000US04003  04003   \n",
       "201104005          26  0500000US04005  04005   \n",
       "201104013          27  0500000US04013  04013   \n",
       "201104015          28  0500000US04015  04015   \n",
       "201104017          29  0500000US04017  04017   \n",
       "...               ...             ...    ...   \n",
       "201654033        4854  0500000US54033  54033   \n",
       "201654039        4855  0500000US54039  54039   \n",
       "201654061        4856  0500000US54061  54061   \n",
       "201654081        4857  0500000US54081  54081   \n",
       "201654107        4858  0500000US54107  54107   \n",
       "201655009        4859  0500000US55009  55009   \n",
       "201655025        4860  0500000US55025  55025   \n",
       "201655027        4861  0500000US55027  55027   \n",
       "201655035        4862  0500000US55035  55035   \n",
       "201655039        4863  0500000US55039  55039   \n",
       "201655055        4864  0500000US55055  55055   \n",
       "201655059        4865  0500000US55059  55059   \n",
       "201655063        4866  0500000US55063  55063   \n",
       "201655071        4867  0500000US55071  55071   \n",
       "201655073        4868  0500000US55073  55073   \n",
       "201655079        4869  0500000US55079  55079   \n",
       "201655087        4870  0500000US55087  55087   \n",
       "201655089        4871  0500000US55089  55089   \n",
       "201655097        4872  0500000US55097  55097   \n",
       "201655101        4873  0500000US55101  55101   \n",
       "201655105        4874  0500000US55105  55105   \n",
       "201655109        4875  0500000US55109  55109   \n",
       "201655117        4876  0500000US55117  55117   \n",
       "201655127        4877  0500000US55127  55127   \n",
       "201655131        4878  0500000US55131  55131   \n",
       "201655133        4879  0500000US55133  55133   \n",
       "201655139        4880  0500000US55139  55139   \n",
       "201655141        4881  0500000US55141  55141   \n",
       "201656021        4882  0500000US56021  56021   \n",
       "201656025        4883  0500000US56025  56025   \n",
       "\n",
       "                                         county  agriculture  construction  \\\n",
       "new_index                                                                    \n",
       "201101003               Baldwin County, Alabama     0.016852      0.083986   \n",
       "201101015               Calhoun County, Alabama     0.007880      0.032057   \n",
       "201101043               Cullman County, Alabama     0.018515      0.063626   \n",
       "201101049                DeKalb County, Alabama     0.018515      0.063626   \n",
       "201101051                Elmore County, Alabama     0.018515      0.063626   \n",
       "201101055                Etowah County, Alabama     0.018515      0.063626   \n",
       "201101069               Houston County, Alabama     0.017374      0.065252   \n",
       "201101073             Jefferson County, Alabama     0.006084      0.061087   \n",
       "201101077            Lauderdale County, Alabama     0.023900      0.090422   \n",
       "201101081                   Lee County, Alabama     0.011975      0.052026   \n",
       "201101083             Limestone County, Alabama     0.018515      0.063626   \n",
       "201101089               Madison County, Alabama     0.003638      0.063403   \n",
       "201101095              Marshall County, Alabama     0.014301      0.098027   \n",
       "201101097                Mobile County, Alabama     0.011873      0.063253   \n",
       "201101101            Montgomery County, Alabama     0.005400      0.039957   \n",
       "201101103                Morgan County, Alabama     0.009305      0.070397   \n",
       "201101115             St. Clair County, Alabama     0.010697      0.080631   \n",
       "201101117                Shelby County, Alabama     0.013908      0.077871   \n",
       "201101121             Talladega County, Alabama     0.018515      0.063626   \n",
       "201101125            Tuscaloosa County, Alabama     0.022729      0.089644   \n",
       "201101127                Walker County, Alabama     0.018515      0.063626   \n",
       "201102020        Anchorage Municipality, Alaska     0.027366      0.057360   \n",
       "201102090  Fairbanks North Star Borough, Alaska     0.052167      0.099509   \n",
       "201102170     Matanuska-Susitna Borough, Alaska     0.069939      0.112447   \n",
       "201104001                Apache County, Arizona     0.018515      0.063626   \n",
       "201104003               Cochise County, Arizona     0.020734      0.056097   \n",
       "201104005              Coconino County, Arizona     0.017770      0.054454   \n",
       "201104013              Maricopa County, Arizona     0.006198      0.066253   \n",
       "201104015                Mohave County, Arizona     0.011238      0.077106   \n",
       "201104017                Navajo County, Arizona     0.018515      0.063626   \n",
       "...                                         ...          ...           ...   \n",
       "201654033        Harrison County, West Virginia     0.052257      0.081446   \n",
       "201654039         Kanawha County, West Virginia     0.017405      0.046901   \n",
       "201654061      Monongalia County, West Virginia     0.019331      0.064805   \n",
       "201654081         Raleigh County, West Virginia     0.019331      0.064805   \n",
       "201654107            Wood County, West Virginia     0.020469      0.077212   \n",
       "201655009               Brown County, Wisconsin     0.011632      0.066020   \n",
       "201655025                Dane County, Wisconsin     0.010851      0.043498   \n",
       "201655027               Dodge County, Wisconsin     0.047311      0.071880   \n",
       "201655035          Eau Claire County, Wisconsin     0.014819      0.040975   \n",
       "201655039         Fond du Lac County, Wisconsin     0.041512      0.066198   \n",
       "201655055           Jefferson County, Wisconsin     0.032603      0.072253   \n",
       "201655059             Kenosha County, Wisconsin     0.012842      0.054538   \n",
       "201655063           La Crosse County, Wisconsin     0.007260      0.041080   \n",
       "201655071           Manitowoc County, Wisconsin     0.033466      0.056320   \n",
       "201655073            Marathon County, Wisconsin     0.039205      0.045925   \n",
       "201655079           Milwaukee County, Wisconsin     0.005206      0.040856   \n",
       "201655087           Outagamie County, Wisconsin     0.010929      0.082346   \n",
       "201655089             Ozaukee County, Wisconsin     0.017353      0.034342   \n",
       "201655097             Portage County, Wisconsin     0.042288      0.045415   \n",
       "201655101              Racine County, Wisconsin     0.011039      0.058076   \n",
       "201655105                Rock County, Wisconsin     0.018481      0.059899   \n",
       "201655109           St. Croix County, Wisconsin     0.015152      0.077924   \n",
       "201655117           Sheboygan County, Wisconsin     0.017158      0.043523   \n",
       "201655127            Walworth County, Wisconsin     0.022594      0.098004   \n",
       "201655131          Washington County, Wisconsin     0.014066      0.061667   \n",
       "201655133            Waukesha County, Wisconsin     0.003460      0.051561   \n",
       "201655139           Winnebago County, Wisconsin     0.011644      0.041022   \n",
       "201655141                Wood County, Wisconsin     0.054501      0.061069   \n",
       "201656021               Laramie County, Wyoming     0.064778      0.047264   \n",
       "201656025               Natrona County, Wyoming     0.099115      0.069455   \n",
       "\n",
       "           manufacturing  wholesale_trade  retail_trade  transport_utilities  \\\n",
       "new_index                                                                      \n",
       "201101003       0.079391         0.027581      0.123280             0.046038   \n",
       "201101015       0.183969         0.017536      0.133418             0.038019   \n",
       "201101043       0.109001         0.027657      0.121484             0.048201   \n",
       "201101049       0.109001         0.027657      0.121484             0.048201   \n",
       "201101051       0.109001         0.027657      0.121484             0.048201   \n",
       "201101055       0.109001         0.027657      0.121484             0.048201   \n",
       "201101069       0.093182         0.041720      0.136903             0.062415   \n",
       "201101073       0.093593         0.030606      0.117545             0.050879   \n",
       "201101077       0.108259         0.034461      0.152775             0.062505   \n",
       "201101081       0.120861         0.012006      0.113500             0.031012   \n",
       "201101083       0.109001         0.027657      0.121484             0.048201   \n",
       "201101089       0.117735         0.017243      0.096425             0.029486   \n",
       "201101095       0.217227         0.041457      0.133881             0.027106   \n",
       "201101097       0.123341         0.031398      0.132165             0.054505   \n",
       "201101101       0.094186         0.024899      0.120144             0.039654   \n",
       "201101103       0.213297         0.031806      0.103293             0.061675   \n",
       "201101115       0.126615         0.057098      0.137118             0.061154   \n",
       "201101117       0.065311         0.037660      0.144272             0.037125   \n",
       "201101121       0.109001         0.027657      0.121484             0.048201   \n",
       "201101125       0.108741         0.022671      0.115294             0.035811   \n",
       "201101127       0.109001         0.027657      0.121484             0.048201   \n",
       "201102020       0.021079         0.021655      0.119391             0.082924   \n",
       "201102090       0.023131         0.031503      0.096909             0.061595   \n",
       "201102170       0.029468         0.011614      0.119858             0.052798   \n",
       "201104001       0.109001         0.027657      0.121484             0.048201   \n",
       "201104003       0.023664         0.037363      0.101816             0.052754   \n",
       "201104005       0.061902         0.008524      0.129436             0.057329   \n",
       "201104013       0.081239         0.027283      0.125761             0.052707   \n",
       "201104015       0.053222         0.010865      0.156779             0.059489   \n",
       "201104017       0.109001         0.027657      0.121484             0.048201   \n",
       "...                  ...              ...           ...                  ...   \n",
       "201654033       0.041997         0.039520      0.143044             0.079076   \n",
       "201654039       0.043511         0.020314      0.112551             0.042439   \n",
       "201654061       0.110679         0.026496      0.119219             0.049516   \n",
       "201654081       0.110679         0.026496      0.119219             0.049516   \n",
       "201654107       0.069721         0.019097      0.162409             0.034408   \n",
       "201655009       0.204324         0.022902      0.130133             0.059497   \n",
       "201655025       0.085430         0.022219      0.099005             0.028650   \n",
       "201655027       0.277360         0.025094      0.109898             0.041694   \n",
       "201655035       0.134874         0.025018      0.150758             0.042310   \n",
       "201655039       0.209342         0.016263      0.104877             0.047177   \n",
       "201655055       0.239923         0.031417      0.111838             0.033613   \n",
       "201655059       0.194387         0.032630      0.119787             0.053561   \n",
       "201655063       0.117299         0.029420      0.139698             0.047006   \n",
       "201655071       0.294886         0.023438      0.122107             0.047168   \n",
       "201655073       0.221681         0.034892      0.118089             0.050850   \n",
       "201655079       0.151928         0.025744      0.098580             0.042440   \n",
       "201655087       0.215747         0.027711      0.109190             0.039578   \n",
       "201655089       0.192271         0.034706      0.116056             0.021589   \n",
       "201655097       0.136377         0.006912      0.145812             0.048438   \n",
       "201655101       0.213810         0.033885      0.109970             0.055805   \n",
       "201655105       0.223351         0.027468      0.129027             0.034653   \n",
       "201655109       0.187480         0.033922      0.105853             0.059818   \n",
       "201655117       0.330605         0.018147      0.113864             0.050047   \n",
       "201655127       0.174083         0.022269      0.107505             0.034885   \n",
       "201655131       0.229442         0.028969      0.131752             0.045507   \n",
       "201655133       0.189171         0.039930      0.109892             0.032850   \n",
       "201655139       0.249727         0.021688      0.123855             0.033924   \n",
       "201655141       0.168087         0.016770      0.128092             0.048241   \n",
       "201656021       0.044145         0.016227      0.152893             0.065061   \n",
       "201656025       0.055505         0.032460      0.139976             0.042372   \n",
       "\n",
       "                ...        wholesale_trade_1  retail_trade_1  \\\n",
       "new_index       ...                                            \n",
       "201101003       ...                 0.029687        0.143542   \n",
       "201101015       ...                 0.014505        0.117222   \n",
       "201101043       ...                 0.027073        0.119457   \n",
       "201101049       ...                 0.029322        0.135833   \n",
       "201101051       ...                 0.027073        0.119457   \n",
       "201101055       ...                 0.041238        0.113706   \n",
       "201101069       ...                 0.044390        0.119499   \n",
       "201101073       ...                 0.029361        0.101286   \n",
       "201101077       ...                 0.027073        0.119457   \n",
       "201101081       ...                 0.011605        0.128486   \n",
       "201101083       ...                 0.027073        0.119457   \n",
       "201101089       ...                 0.015692        0.117546   \n",
       "201101095       ...                 0.022522        0.114291   \n",
       "201101097       ...                 0.031880        0.139225   \n",
       "201101101       ...                 0.024690        0.134467   \n",
       "201101103       ...                 0.023668        0.125086   \n",
       "201101115       ...                 0.027073        0.119457   \n",
       "201101117       ...                 0.034675        0.114391   \n",
       "201101121       ...                 0.027073        0.119457   \n",
       "201101125       ...                 0.022688        0.113499   \n",
       "201101127       ...                 0.027073        0.119457   \n",
       "201102020       ...                 0.030751        0.117070   \n",
       "201102090       ...                 0.009886        0.142124   \n",
       "201102170       ...                 0.016445        0.107263   \n",
       "201104001       ...                 0.027073        0.119457   \n",
       "201104003       ...                 0.027073        0.119457   \n",
       "201104005       ...                 0.013723        0.126760   \n",
       "201104013       ...                 0.028882        0.120632   \n",
       "201104015       ...                 0.011893        0.130677   \n",
       "201104017       ...                 0.027073        0.119457   \n",
       "...             ...                      ...             ...   \n",
       "201654033       ...                 0.022976        0.118177   \n",
       "201654039       ...                 0.023300        0.079815   \n",
       "201654061       ...                 0.021541        0.073314   \n",
       "201654081       ...                 0.025861        0.119262   \n",
       "201654107       ...                 0.014593        0.131056   \n",
       "201655009       ...                 0.031923        0.105683   \n",
       "201655025       ...                 0.017753        0.100363   \n",
       "201655027       ...                 0.020326        0.105413   \n",
       "201655035       ...                 0.027088        0.193205   \n",
       "201655039       ...                 0.022365        0.103813   \n",
       "201655055       ...                 0.016530        0.118884   \n",
       "201655059       ...                 0.033557        0.169675   \n",
       "201655063       ...                 0.029254        0.127378   \n",
       "201655071       ...                 0.013362        0.092097   \n",
       "201655073       ...                 0.041016        0.109750   \n",
       "201655079       ...                 0.027123        0.110877   \n",
       "201655087       ...                 0.033813        0.127579   \n",
       "201655089       ...                 0.030211        0.109572   \n",
       "201655097       ...                 0.015865        0.125702   \n",
       "201655101       ...                 0.029709        0.125592   \n",
       "201655105       ...                 0.033063        0.115378   \n",
       "201655109       ...                 0.023844        0.096718   \n",
       "201655117       ...                 0.017259        0.113262   \n",
       "201655127       ...                 0.032571        0.134970   \n",
       "201655131       ...                 0.025311        0.095768   \n",
       "201655133       ...                 0.042637        0.112053   \n",
       "201655139       ...                 0.033121        0.116369   \n",
       "201655141       ...                 0.021737        0.087108   \n",
       "201656021       ...                 0.009039        0.116443   \n",
       "201656025       ...                 0.034181        0.103022   \n",
       "\n",
       "           transport_utilities_1  information_1  \\\n",
       "new_index                                         \n",
       "201101003               0.050436       0.014955   \n",
       "201101015               0.037962       0.020691   \n",
       "201101043               0.048909       0.019094   \n",
       "201101049               0.054265       0.014610   \n",
       "201101051               0.048909       0.019094   \n",
       "201101055               0.052478       0.008981   \n",
       "201101069               0.096198       0.014208   \n",
       "201101073               0.053590       0.021607   \n",
       "201101077               0.048909       0.019094   \n",
       "201101081               0.025439       0.017798   \n",
       "201101083               0.048909       0.019094   \n",
       "201101089               0.034726       0.030083   \n",
       "201101095               0.039551       0.013772   \n",
       "201101097               0.054112       0.013870   \n",
       "201101101               0.028985       0.011178   \n",
       "201101103               0.029213       0.018433   \n",
       "201101115               0.048909       0.019094   \n",
       "201101117               0.037506       0.029285   \n",
       "201101121               0.048909       0.019094   \n",
       "201101125               0.034689       0.015433   \n",
       "201101127               0.048909       0.019094   \n",
       "201102020               0.062956       0.020289   \n",
       "201102090               0.072324       0.007935   \n",
       "201102170               0.091003       0.020109   \n",
       "201104001               0.048909       0.019094   \n",
       "201104003               0.048909       0.019094   \n",
       "201104005               0.046931       0.007601   \n",
       "201104013               0.051141       0.019078   \n",
       "201104015               0.071125       0.026495   \n",
       "201104017               0.048909       0.019094   \n",
       "...                          ...            ...   \n",
       "201654033               0.050671       0.008854   \n",
       "201654039               0.042872       0.029697   \n",
       "201654061               0.044547       0.007930   \n",
       "201654081               0.050540       0.017906   \n",
       "201654107               0.013842       0.015399   \n",
       "201655009               0.059434       0.013720   \n",
       "201655025               0.028759       0.027053   \n",
       "201655027               0.047324       0.012690   \n",
       "201655035               0.051113       0.012940   \n",
       "201655039               0.056220       0.019669   \n",
       "201655055               0.041942       0.011990   \n",
       "201655059               0.056785       0.010555   \n",
       "201655063               0.042912       0.032632   \n",
       "201655071               0.060837       0.008315   \n",
       "201655073               0.035602       0.006382   \n",
       "201655079               0.047110       0.017094   \n",
       "201655087               0.036342       0.008640   \n",
       "201655089               0.037420       0.012823   \n",
       "201655097               0.051065       0.008131   \n",
       "201655101               0.061490       0.013684   \n",
       "201655105               0.038247       0.026341   \n",
       "201655109               0.052042       0.023498   \n",
       "201655117               0.028649       0.010139   \n",
       "201655127               0.034615       0.011609   \n",
       "201655131               0.035803       0.015786   \n",
       "201655133               0.038018       0.014992   \n",
       "201655139               0.030078       0.022100   \n",
       "201655141               0.067083       0.013280   \n",
       "201656021               0.061820       0.033988   \n",
       "201656025               0.057952       0.025090   \n",
       "\n",
       "           finance_insurance_realestate_1  prof_scientific_waste_1  \\\n",
       "new_index                                                            \n",
       "201101003                        0.059526                 0.086022   \n",
       "201101015                        0.020522                 0.097882   \n",
       "201101043                        0.060985                 0.096501   \n",
       "201101049                        0.026380                 0.080747   \n",
       "201101051                        0.060985                 0.096501   \n",
       "201101055                        0.038159                 0.045908   \n",
       "201101069                        0.038269                 0.091149   \n",
       "201101073                        0.087961                 0.116549   \n",
       "201101077                        0.060985                 0.096501   \n",
       "201101081                        0.040722                 0.076828   \n",
       "201101083                        0.060985                 0.096501   \n",
       "201101089                        0.040669                 0.175376   \n",
       "201101095                        0.036929                 0.062762   \n",
       "201101097                        0.056813                 0.097774   \n",
       "201101101                        0.053563                 0.102832   \n",
       "201101103                        0.044374                 0.081258   \n",
       "201101115                        0.060985                 0.096501   \n",
       "201101117                        0.112044                 0.137249   \n",
       "201101121                        0.060985                 0.096501   \n",
       "201101125                        0.054224                 0.067698   \n",
       "201101127                        0.060985                 0.096501   \n",
       "201102020                        0.049245                 0.110399   \n",
       "201102090                        0.036130                 0.077480   \n",
       "201102170                        0.042721                 0.086338   \n",
       "201104001                        0.060985                 0.096501   \n",
       "201104003                        0.060985                 0.096501   \n",
       "201104005                        0.051573                 0.065732   \n",
       "201104013                        0.099774                 0.130022   \n",
       "201104015                        0.052163                 0.076398   \n",
       "201104017                        0.060985                 0.096501   \n",
       "...                                   ...                      ...   \n",
       "201654033                        0.037357                 0.065794   \n",
       "201654039                        0.065889                 0.100224   \n",
       "201654061                        0.046173                 0.109550   \n",
       "201654081                        0.060702                 0.100859   \n",
       "201654107                        0.040665                 0.051311   \n",
       "201655009                        0.073024                 0.084382   \n",
       "201655025                        0.082944                 0.137849   \n",
       "201655027                        0.044261                 0.058373   \n",
       "201655035                        0.059241                 0.069514   \n",
       "201655039                        0.046906                 0.049081   \n",
       "201655055                        0.055012                 0.072291   \n",
       "201655059                        0.040375                 0.085926   \n",
       "201655063                        0.053741                 0.071180   \n",
       "201655071                        0.044403                 0.038843   \n",
       "201655073                        0.090070                 0.067402   \n",
       "201655079                        0.061934                 0.106110   \n",
       "201655087                        0.066174                 0.090829   \n",
       "201655089                        0.064551                 0.108895   \n",
       "201655097                        0.121597                 0.056865   \n",
       "201655101                        0.053119                 0.086634   \n",
       "201655105                        0.041678                 0.066037   \n",
       "201655109                        0.069111                 0.108966   \n",
       "201655117                        0.067037                 0.053613   \n",
       "201655127                        0.037276                 0.083076   \n",
       "201655131                        0.062445                 0.080276   \n",
       "201655133                        0.082146                 0.110605   \n",
       "201655139                        0.059290                 0.080581   \n",
       "201655141                        0.068585                 0.055542   \n",
       "201656021                        0.038453                 0.071162   \n",
       "201656025                        0.062317                 0.074406   \n",
       "\n",
       "           edu_health_1 arts_recreation_1   other_1  public_admin_1  \n",
       "new_index                                                            \n",
       "201101003      0.221214          0.113281  0.048301        0.036560  \n",
       "201101015      0.204400          0.081013  0.051918        0.098368  \n",
       "201101043      0.240508          0.093014  0.048994        0.053334  \n",
       "201101049      0.203203          0.053307  0.068601        0.042632  \n",
       "201101051      0.240508          0.093014  0.048994        0.053334  \n",
       "201101055      0.250481          0.113808  0.051323        0.062973  \n",
       "201101069      0.225213          0.090322  0.061995        0.051472  \n",
       "201101073      0.272641          0.075168  0.058147        0.044486  \n",
       "201101077      0.240508          0.093014  0.048994        0.053334  \n",
       "201101081      0.288127          0.103079  0.061226        0.039910  \n",
       "201101083      0.240508          0.093014  0.048994        0.053334  \n",
       "201101089      0.179244          0.081932  0.051930        0.087763  \n",
       "201101095      0.198167          0.063507  0.053378        0.043829  \n",
       "201101097      0.233898          0.087059  0.059638        0.039582  \n",
       "201101101      0.216640          0.102690  0.057959        0.119482  \n",
       "201101103      0.193365          0.075295  0.059207        0.033121  \n",
       "201101115      0.240508          0.093014  0.048994        0.053334  \n",
       "201101117      0.197602          0.061784  0.059296        0.046985  \n",
       "201101121      0.240508          0.093014  0.048994        0.053334  \n",
       "201101125      0.284911          0.119719  0.042211        0.048357  \n",
       "201101127      0.240508          0.093014  0.048994        0.053334  \n",
       "201102020      0.249707          0.100512  0.042225        0.111625  \n",
       "201102090      0.217588          0.078668  0.049263        0.150334  \n",
       "201102170      0.251476          0.078537  0.039822        0.083070  \n",
       "201104001      0.240508          0.093014  0.048994        0.053334  \n",
       "201104003      0.240508          0.093014  0.048994        0.053334  \n",
       "201104005      0.247508          0.201433  0.033754        0.071978  \n",
       "201104013      0.203000          0.097778  0.048240        0.046061  \n",
       "201104015      0.189562          0.174207  0.034375        0.076340  \n",
       "201104017      0.240508          0.093014  0.048994        0.053334  \n",
       "...                 ...               ...       ...             ...  \n",
       "201654033      0.296526          0.085022  0.047601        0.115786  \n",
       "201654039      0.270667          0.100113  0.040842        0.112526  \n",
       "201654061      0.360388          0.121354  0.035513        0.059201  \n",
       "201654081      0.238304          0.097315  0.048328        0.049026  \n",
       "201654107      0.320483          0.099258  0.045223        0.089474  \n",
       "201655009      0.202846          0.093170  0.039007        0.020846  \n",
       "201655025      0.285833          0.090658  0.039668        0.044714  \n",
       "201655027      0.185140          0.063427  0.048549        0.030040  \n",
       "201655035      0.267207          0.079175  0.047544        0.033937  \n",
       "201655039      0.209634          0.063600  0.035435        0.045790  \n",
       "201655055      0.238870          0.077360  0.043771        0.026514  \n",
       "201655059      0.225782          0.084677  0.045349        0.048229  \n",
       "201655063      0.298961          0.108936  0.046355        0.032293  \n",
       "201655071      0.210480          0.062227  0.037088        0.020994  \n",
       "201655073      0.227370          0.071343  0.035559        0.027045  \n",
       "201655079      0.258274          0.097210  0.044666        0.035156  \n",
       "201655087      0.207668          0.079542  0.031116        0.027592  \n",
       "201655089      0.233125          0.077941  0.032854        0.033925  \n",
       "201655097      0.258078          0.072386  0.036948        0.027890  \n",
       "201655101      0.207000          0.076496  0.040780        0.032095  \n",
       "201655105      0.212013          0.071704  0.030623        0.029149  \n",
       "201655109      0.196570          0.070616  0.057046        0.037007  \n",
       "201655117      0.185135          0.076792  0.039122        0.025314  \n",
       "201655127      0.225702          0.106738  0.033728        0.025108  \n",
       "201655131      0.207379          0.075402  0.050286        0.037876  \n",
       "201655133      0.223792          0.076854  0.036258        0.027043  \n",
       "201655139      0.199925          0.090166  0.043299        0.024915  \n",
       "201655141      0.256396          0.064132  0.034595        0.043448  \n",
       "201656021      0.259028          0.067737  0.059652        0.127411  \n",
       "201656025      0.262701          0.086711  0.050420        0.036316  \n",
       "\n",
       "[4884 rows x 31 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_agri_fish_mine</th>\n",
       "      <th>agri_fish_hunt</th>\n",
       "      <th>mining_quarrying_oilgas_extract</th>\n",
       "      <th>construction</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>wholesale_trade</th>\n",
       "      <th>retail_trade</th>\n",
       "      <th>...</th>\n",
       "      <th>mgmt_1</th>\n",
       "      <th>admin_sup_1</th>\n",
       "      <th>total_edu_health_social_1</th>\n",
       "      <th>edu_serv_1</th>\n",
       "      <th>health_social_1</th>\n",
       "      <th>total_arts_ent_acc_food_1</th>\n",
       "      <th>arts_ent_rec_1</th>\n",
       "      <th>acc_food_serv_1</th>\n",
       "      <th>other_ser_1</th>\n",
       "      <th>pub_admin_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.038651</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>0.035264</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.032354</td>\n",
       "      <td>0.060475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01003</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.093891</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027452</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.029922</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>0.043733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101005</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01005</td>\n",
       "      <td>0.026422</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.045156</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.068945</td>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>0.052426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101007</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>01007</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.043590</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088554</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.019591</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.041305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101009</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>01009</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.031778</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.039811</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.026629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.038854</td>\n",
       "      <td>0.047215</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.029518</td>\n",
       "      <td>0.044929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101011</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>01011</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>0.038094</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>0.073537</td>\n",
       "      <td>0.037080</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.073923</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.070545</td>\n",
       "      <td>0.066220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101013</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>01013</td>\n",
       "      <td>0.053413</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.061953</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.036859</td>\n",
       "      <td>0.037142</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.032644</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>0.045637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101015</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>01015</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>0.032316</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.046204</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030095</td>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>0.030489</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>0.060025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101017</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>01017</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.051457</td>\n",
       "      <td>0.032435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030672</td>\n",
       "      <td>0.037197</td>\n",
       "      <td>0.056113</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>0.015714</td>\n",
       "      <td>0.104354</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.025457</td>\n",
       "      <td>0.049391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101019</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>01019</td>\n",
       "      <td>0.053501</td>\n",
       "      <td>0.054154</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.036568</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.026765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023108</td>\n",
       "      <td>0.050116</td>\n",
       "      <td>0.065870</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.019458</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101021</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>01021</td>\n",
       "      <td>0.042588</td>\n",
       "      <td>0.035746</td>\n",
       "      <td>0.057889</td>\n",
       "      <td>0.040538</td>\n",
       "      <td>0.045253</td>\n",
       "      <td>0.038276</td>\n",
       "      <td>0.026190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.034679</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.026181</td>\n",
       "      <td>0.013099</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.052831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101023</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>01023</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>0.063933</td>\n",
       "      <td>0.077112</td>\n",
       "      <td>0.044249</td>\n",
       "      <td>0.083887</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042448</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>0.040801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101025</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>01025</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.041074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042266</td>\n",
       "      <td>0.063555</td>\n",
       "      <td>0.057882</td>\n",
       "      <td>0.025943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.015537</td>\n",
       "      <td>0.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101027</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>01027</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>0.032771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046523</td>\n",
       "      <td>0.040635</td>\n",
       "      <td>0.027448</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.039196</td>\n",
       "      <td>0.048040</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.046093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101029</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>01029</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041149</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>0.046739</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.038755</td>\n",
       "      <td>0.045622</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.040023</td>\n",
       "      <td>0.053626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101031</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>01031</td>\n",
       "      <td>0.032148</td>\n",
       "      <td>0.027024</td>\n",
       "      <td>0.075205</td>\n",
       "      <td>0.037264</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>0.025593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046305</td>\n",
       "      <td>0.043382</td>\n",
       "      <td>0.055708</td>\n",
       "      <td>0.032983</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>0.028947</td>\n",
       "      <td>0.065745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101033</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>01033</td>\n",
       "      <td>0.042547</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.064460</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.040485</td>\n",
       "      <td>0.050103</td>\n",
       "      <td>0.036449</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.042354</td>\n",
       "      <td>0.041571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101035</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>01035</td>\n",
       "      <td>0.140091</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052834</td>\n",
       "      <td>0.060091</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>0.072586</td>\n",
       "      <td>0.031211</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.050686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101037</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>01037</td>\n",
       "      <td>0.075468</td>\n",
       "      <td>0.078493</td>\n",
       "      <td>0.050367</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>0.042824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025432</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.019234</td>\n",
       "      <td>0.069338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101039</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>01039</td>\n",
       "      <td>0.048205</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>0.127769</td>\n",
       "      <td>0.034754</td>\n",
       "      <td>0.041834</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0.049613</td>\n",
       "      <td>0.030926</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.017069</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>0.042183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101041</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>01041</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.032309</td>\n",
       "      <td>0.146805</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.037623</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037194</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0.034347</td>\n",
       "      <td>0.013392</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>0.050584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101043</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>01043</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.030104</td>\n",
       "      <td>0.059925</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>0.040432</td>\n",
       "      <td>0.045191</td>\n",
       "      <td>0.038170</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.026283</td>\n",
       "      <td>0.050447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101045</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>01045</td>\n",
       "      <td>0.028373</td>\n",
       "      <td>0.028743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036479</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.040993</td>\n",
       "      <td>0.049067</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.063236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101047</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>01047</td>\n",
       "      <td>0.031411</td>\n",
       "      <td>0.030805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>0.045687</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.051120</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>0.059994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101049</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>01049</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.030962</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.042874</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.044823</td>\n",
       "      <td>0.058982</td>\n",
       "      <td>0.038299</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>0.024305</td>\n",
       "      <td>0.045895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101051</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>01051</td>\n",
       "      <td>0.030874</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>0.038913</td>\n",
       "      <td>0.043618</td>\n",
       "      <td>0.042489</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>0.018574</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.058108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101053</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>01053</td>\n",
       "      <td>0.049439</td>\n",
       "      <td>0.049817</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>0.027062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025270</td>\n",
       "      <td>0.038714</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>0.032452</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.032507</td>\n",
       "      <td>0.046644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101055</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>01055</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>0.046870</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163261</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.037364</td>\n",
       "      <td>0.041034</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.015083</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.014655</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.050626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101057</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>01057</td>\n",
       "      <td>0.059308</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.097018</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>0.042148</td>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>0.037220</td>\n",
       "      <td>0.058983</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.058146</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.052229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101059</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>01059</td>\n",
       "      <td>0.035935</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.048265</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>0.024484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.042038</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655129</th>\n",
       "      <td>18823</td>\n",
       "      <td>18823</td>\n",
       "      <td>55129</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>0.029626</td>\n",
       "      <td>0.110842</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>0.039149</td>\n",
       "      <td>0.045589</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.026003</td>\n",
       "      <td>0.041028</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.036955</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.024568</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.052563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655131</th>\n",
       "      <td>18824</td>\n",
       "      <td>18824</td>\n",
       "      <td>55131</td>\n",
       "      <td>0.033418</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.052911</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.047754</td>\n",
       "      <td>0.024611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.033470</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.028379</td>\n",
       "      <td>0.055685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655133</th>\n",
       "      <td>18825</td>\n",
       "      <td>18825</td>\n",
       "      <td>55133</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.070681</td>\n",
       "      <td>0.043071</td>\n",
       "      <td>0.049311</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.037317</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.023636</td>\n",
       "      <td>0.048317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655135</th>\n",
       "      <td>18826</td>\n",
       "      <td>18826</td>\n",
       "      <td>55135</td>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.029843</td>\n",
       "      <td>0.053748</td>\n",
       "      <td>0.052883</td>\n",
       "      <td>0.058848</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.026939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.038673</td>\n",
       "      <td>0.047750</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.011495</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.050309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655137</th>\n",
       "      <td>18827</td>\n",
       "      <td>18827</td>\n",
       "      <td>55137</td>\n",
       "      <td>0.035212</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>0.047843</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>0.021638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.035199</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.031572</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.049673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655139</th>\n",
       "      <td>18828</td>\n",
       "      <td>18828</td>\n",
       "      <td>55139</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>0.049006</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.043036</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147481</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.047213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655141</th>\n",
       "      <td>18829</td>\n",
       "      <td>18829</td>\n",
       "      <td>55141</td>\n",
       "      <td>0.039303</td>\n",
       "      <td>0.039496</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.040181</td>\n",
       "      <td>0.051318</td>\n",
       "      <td>0.038525</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.061870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656001</th>\n",
       "      <td>18830</td>\n",
       "      <td>18830</td>\n",
       "      <td>56001</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.034441</td>\n",
       "      <td>0.079392</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.044874</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.022531</td>\n",
       "      <td>0.064585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656003</th>\n",
       "      <td>18831</td>\n",
       "      <td>18831</td>\n",
       "      <td>56003</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>0.060781</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>0.071590</td>\n",
       "      <td>0.021056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>0.036154</td>\n",
       "      <td>0.038228</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.042665</td>\n",
       "      <td>0.048249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656005</th>\n",
       "      <td>18832</td>\n",
       "      <td>18832</td>\n",
       "      <td>56005</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.032282</td>\n",
       "      <td>0.072397</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.046719</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.039328</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656007</th>\n",
       "      <td>18833</td>\n",
       "      <td>18833</td>\n",
       "      <td>56007</td>\n",
       "      <td>0.058095</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.076264</td>\n",
       "      <td>0.049095</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>0.037813</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.035710</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.037850</td>\n",
       "      <td>0.048674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656009</th>\n",
       "      <td>18834</td>\n",
       "      <td>18834</td>\n",
       "      <td>56009</td>\n",
       "      <td>0.077904</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.085895</td>\n",
       "      <td>0.053048</td>\n",
       "      <td>0.042797</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.016037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.031671</td>\n",
       "      <td>0.015754</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>0.048932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656011</th>\n",
       "      <td>18835</td>\n",
       "      <td>18835</td>\n",
       "      <td>56011</td>\n",
       "      <td>0.057260</td>\n",
       "      <td>0.031204</td>\n",
       "      <td>0.071083</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.028069</td>\n",
       "      <td>0.039697</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.050690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656013</th>\n",
       "      <td>18836</td>\n",
       "      <td>18836</td>\n",
       "      <td>56013</td>\n",
       "      <td>0.068965</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.079768</td>\n",
       "      <td>0.038635</td>\n",
       "      <td>0.062627</td>\n",
       "      <td>0.040480</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027359</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0.046236</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.025353</td>\n",
       "      <td>0.050301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656015</th>\n",
       "      <td>18837</td>\n",
       "      <td>18837</td>\n",
       "      <td>56015</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.028270</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>0.030383</td>\n",
       "      <td>0.038749</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057113</td>\n",
       "      <td>0.042448</td>\n",
       "      <td>0.054771</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>0.050975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656017</th>\n",
       "      <td>18838</td>\n",
       "      <td>18838</td>\n",
       "      <td>56017</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.049426</td>\n",
       "      <td>0.070867</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.066612</td>\n",
       "      <td>0.094922</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.048175</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.047456</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.050949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656019</th>\n",
       "      <td>18839</td>\n",
       "      <td>18839</td>\n",
       "      <td>56019</td>\n",
       "      <td>0.058270</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.067507</td>\n",
       "      <td>0.065758</td>\n",
       "      <td>0.060360</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.034055</td>\n",
       "      <td>0.050224</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.044630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656021</th>\n",
       "      <td>18840</td>\n",
       "      <td>18840</td>\n",
       "      <td>56021</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.061011</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.026209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.038115</td>\n",
       "      <td>0.045142</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.016366</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.026538</td>\n",
       "      <td>0.051785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656023</th>\n",
       "      <td>18841</td>\n",
       "      <td>18841</td>\n",
       "      <td>56023</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.040523</td>\n",
       "      <td>0.073948</td>\n",
       "      <td>0.045834</td>\n",
       "      <td>0.060904</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023534</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.025856</td>\n",
       "      <td>0.047571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656025</th>\n",
       "      <td>18842</td>\n",
       "      <td>18842</td>\n",
       "      <td>56025</td>\n",
       "      <td>0.063043</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.068105</td>\n",
       "      <td>0.041928</td>\n",
       "      <td>0.042170</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032089</td>\n",
       "      <td>0.035244</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.031176</td>\n",
       "      <td>0.051020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656027</th>\n",
       "      <td>18843</td>\n",
       "      <td>18843</td>\n",
       "      <td>56027</td>\n",
       "      <td>0.040942</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0.129650</td>\n",
       "      <td>0.054980</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043930</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.049189</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656029</th>\n",
       "      <td>18844</td>\n",
       "      <td>18844</td>\n",
       "      <td>56029</td>\n",
       "      <td>0.062119</td>\n",
       "      <td>0.037165</td>\n",
       "      <td>0.088835</td>\n",
       "      <td>0.046289</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.048912</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032530</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.052824</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.029926</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.054524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656031</th>\n",
       "      <td>18845</td>\n",
       "      <td>18845</td>\n",
       "      <td>56031</td>\n",
       "      <td>0.053118</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.029459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656033</th>\n",
       "      <td>18846</td>\n",
       "      <td>18846</td>\n",
       "      <td>56033</td>\n",
       "      <td>0.052933</td>\n",
       "      <td>0.037406</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.044244</td>\n",
       "      <td>0.042612</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.031365</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>0.030403</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.043996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656035</th>\n",
       "      <td>18847</td>\n",
       "      <td>18847</td>\n",
       "      <td>56035</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>0.017572</td>\n",
       "      <td>0.058726</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.035776</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.053497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656037</th>\n",
       "      <td>18848</td>\n",
       "      <td>18848</td>\n",
       "      <td>56037</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.075264</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.086160</td>\n",
       "      <td>0.039580</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.027795</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.028321</td>\n",
       "      <td>0.049015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656039</th>\n",
       "      <td>18849</td>\n",
       "      <td>18849</td>\n",
       "      <td>56039</td>\n",
       "      <td>0.021778</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.014786</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.045060</td>\n",
       "      <td>0.039649</td>\n",
       "      <td>0.020742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036911</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>0.036289</td>\n",
       "      <td>0.046339</td>\n",
       "      <td>0.023790</td>\n",
       "      <td>0.033171</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.035484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656041</th>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>56041</td>\n",
       "      <td>0.082789</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>0.091593</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>0.019468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.028079</td>\n",
       "      <td>0.026542</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.044609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656043</th>\n",
       "      <td>18851</td>\n",
       "      <td>18851</td>\n",
       "      <td>56043</td>\n",
       "      <td>0.033051</td>\n",
       "      <td>0.027330</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0.050269</td>\n",
       "      <td>0.047006</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.025249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.057413</td>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.052542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656045</th>\n",
       "      <td>18852</td>\n",
       "      <td>18852</td>\n",
       "      <td>56045</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>0.039771</td>\n",
       "      <td>0.068864</td>\n",
       "      <td>0.039209</td>\n",
       "      <td>0.059512</td>\n",
       "      <td>0.075895</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042715</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>0.024594</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.042459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18853 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  index   fips  total_agri_fish_mine  agri_fish_hunt  \\\n",
       "new_index                                                                   \n",
       "201101001           0      0  01001              0.038453        0.038651   \n",
       "201101003           1      1  01003              0.038482        0.031718   \n",
       "201101005           2      2  01005              0.026422        0.023638   \n",
       "201101007           3      3  01007              0.054425        0.055420   \n",
       "201101009           4      4  01009              0.033389        0.031778   \n",
       "201101011           5      5  01011              0.039810        0.039810   \n",
       "201101013           6      6  01013              0.053413        0.054747   \n",
       "201101015           7      7  01015              0.032432        0.032480   \n",
       "201101017           8      8  01017              0.033473        0.033801   \n",
       "201101019           9      9  01019              0.053501        0.054154   \n",
       "201101021          10     10  01021              0.042588        0.035746   \n",
       "201101023          11     11  01023              0.065545        0.063933   \n",
       "201101025          12     12  01025              0.035789        0.041074   \n",
       "201101027          13     13  01027              0.034791        0.032771   \n",
       "201101029          14     14  01029              0.050712        0.049971   \n",
       "201101031          15     15  01031              0.032148        0.027024   \n",
       "201101033          16     16  01033              0.042547        0.036987   \n",
       "201101035          17     17  01035              0.140091        0.078342   \n",
       "201101037          18     18  01037              0.075468        0.078493   \n",
       "201101039          19     19  01039              0.048205        0.037652   \n",
       "201101041          20     20  01041              0.034675        0.032309   \n",
       "201101043          21     21  01043              0.039981        0.030104   \n",
       "201101045          22     22  01045              0.028373        0.028743   \n",
       "201101047          23     23  01047              0.031411        0.030805   \n",
       "201101049          24     24  01049              0.032573        0.030864   \n",
       "201101051          25     25  01051              0.030874        0.030562   \n",
       "201101053          26     26  01053              0.049439        0.049817   \n",
       "201101055          27     27  01055              0.016638        0.016438   \n",
       "201101057          28     28  01057              0.059308        0.045700   \n",
       "201101059          29     29  01059              0.035935        0.034830   \n",
       "...               ...    ...    ...                   ...             ...   \n",
       "201655129       18823  18823  55129              0.030787        0.029626   \n",
       "201655131       18824  18824  55131              0.033418        0.031374   \n",
       "201655133       18825  18825  55133              0.025591        0.022200   \n",
       "201655135       18826  18826  55135              0.030160        0.029843   \n",
       "201655137       18827  18827  55137              0.035212        0.035500   \n",
       "201655139       18828  18828  55139              0.030307        0.029802   \n",
       "201655141       18829  18829  55141              0.039303        0.039496   \n",
       "201656001       18830  18830  56001              0.049133        0.034441   \n",
       "201656003       18831  18831  56003              0.054400        0.033383   \n",
       "201656005       18832  18832  56005              0.071601        0.032282   \n",
       "201656007       18833  18833  56007              0.058095        0.027607   \n",
       "201656009       18834  18834  56009              0.077904        0.036032   \n",
       "201656011       18835  18835  56011              0.057260        0.031204   \n",
       "201656013       18836  18836  56013              0.068965        0.034137   \n",
       "201656015       18837  18837  56015              0.035370        0.028270   \n",
       "201656017       18838  18838  56017              0.066995        0.049426   \n",
       "201656019       18839  18839  56019              0.058270        0.027088   \n",
       "201656021       18840  18840  56021              0.053369        0.031811   \n",
       "201656023       18841  18841  56023              0.069474        0.040523   \n",
       "201656025       18842  18842  56025              0.063043        0.020677   \n",
       "201656027       18843  18843  56027              0.040942        0.032844   \n",
       "201656029       18844  18844  56029              0.062119        0.037165   \n",
       "201656031       18845  18845  56031              0.053118        0.026133   \n",
       "201656033       18846  18846  56033              0.052933        0.037406   \n",
       "201656035       18847  18847  56035              0.051157        0.017572   \n",
       "201656037       18848  18848  56037              0.073974        0.017062   \n",
       "201656039       18849  18849  56039              0.021778        0.022830   \n",
       "201656041       18850  18850  56041              0.082789        0.034686   \n",
       "201656043       18851  18851  56043              0.033051        0.027330   \n",
       "201656045       18852  18852  56045              0.066468        0.039771   \n",
       "\n",
       "           mining_quarrying_oilgas_extract  construction  manufacturing  \\\n",
       "new_index                                                                 \n",
       "201101001                         0.027040      0.036704       0.053763   \n",
       "201101003                         0.093891      0.034880       0.048625   \n",
       "201101005                         0.044943      0.033184       0.045156   \n",
       "201101007                         0.041394      0.036440       0.043590   \n",
       "201101009                         0.067470      0.041016       0.039811   \n",
       "201101011                         0.000000      0.046386       0.038094   \n",
       "201101013                         0.000000      0.033347       0.035559   \n",
       "201101015                         0.032316      0.037765       0.048511   \n",
       "201101017                         0.000000      0.038750       0.047168   \n",
       "201101019                         0.018821      0.036568       0.038213   \n",
       "201101021                         0.057889      0.040538       0.045253   \n",
       "201101023                         0.077112      0.044249       0.083887   \n",
       "201101025                         0.000000      0.042266       0.063555   \n",
       "201101027                         0.000000      0.046523       0.040635   \n",
       "201101029                         0.000000      0.041149       0.044286   \n",
       "201101031                         0.075205      0.037264       0.031650   \n",
       "201101033                         0.064460      0.048375       0.048611   \n",
       "201101035                         0.000000      0.052834       0.060091   \n",
       "201101037                         0.050367      0.053836       0.042824   \n",
       "201101039                         0.127769      0.034754       0.041834   \n",
       "201101041                         0.146805      0.035549       0.037623   \n",
       "201101043                         0.059925      0.032815       0.040207   \n",
       "201101045                         0.000000      0.036479       0.043375   \n",
       "201101047                         0.000000      0.043947       0.048475   \n",
       "201101049                         0.074730      0.030962       0.036114   \n",
       "201101051                         0.044875      0.038913       0.043618   \n",
       "201101053                         0.049080      0.035826       0.045707   \n",
       "201101055                         0.046870      0.025226       0.032633   \n",
       "201101057                         0.097018      0.049267       0.042148   \n",
       "201101059                         0.048265      0.023859       0.033649   \n",
       "...                                    ...           ...            ...   \n",
       "201655129                         0.110842      0.039680       0.039149   \n",
       "201655131                         0.052911      0.043691       0.046476   \n",
       "201655133                         0.070681      0.043071       0.049311   \n",
       "201655135                         0.053748      0.052883       0.058848   \n",
       "201655137                         0.028212      0.047843       0.049436   \n",
       "201655139                         0.049006      0.042554       0.045391   \n",
       "201655141                         0.017998      0.053359       0.054011   \n",
       "201656001                         0.079392      0.044423       0.044874   \n",
       "201656003                         0.070642      0.060781       0.053903   \n",
       "201656005                         0.072397      0.036013       0.062939   \n",
       "201656007                         0.076264      0.049095       0.077319   \n",
       "201656009                         0.085895      0.053048       0.042797   \n",
       "201656011                         0.071083      0.045317       0.033799   \n",
       "201656013                         0.079768      0.038635       0.062627   \n",
       "201656015                         0.094530      0.030383       0.038749   \n",
       "201656017                         0.070867      0.024251       0.066612   \n",
       "201656019                         0.067125      0.067507       0.065758   \n",
       "201656021                         0.061011      0.039187       0.052240   \n",
       "201656023                         0.073948      0.045834       0.060904   \n",
       "201656025                         0.068105      0.041928       0.042170   \n",
       "201656027                         0.129650      0.054980       0.040618   \n",
       "201656029                         0.088835      0.046289       0.047736   \n",
       "201656031                         0.076508      0.049659       0.031798   \n",
       "201656033                         0.070312      0.036946       0.044244   \n",
       "201656035                         0.058726      0.050062       0.020128   \n",
       "201656037                         0.075264      0.040446       0.086160   \n",
       "201656039                         0.014786      0.051270       0.045060   \n",
       "201656041                         0.091593      0.025807       0.056032   \n",
       "201656043                         0.052429      0.050269       0.047006   \n",
       "201656045                         0.068864      0.039209       0.059512   \n",
       "\n",
       "           wholesale_trade  retail_trade     ...         mgmt_1  admin_sup_1  \\\n",
       "new_index                                    ...                               \n",
       "201101001         0.046205      0.024608     ...       0.000000     0.034921   \n",
       "201101003         0.050396      0.024145     ...       0.000000     0.027452   \n",
       "201101005         0.030687      0.031284     ...       0.000000     0.019501   \n",
       "201101007         0.052219      0.021749     ...       0.088554     0.032778   \n",
       "201101009         0.041193      0.026629     ...       0.000000     0.033605   \n",
       "201101011         0.084638      0.029305     ...       0.000000     0.002595   \n",
       "201101013         0.061953      0.027078     ...       0.000000     0.038397   \n",
       "201101015         0.046204      0.028544     ...       0.000000     0.030095   \n",
       "201101017         0.051457      0.032435     ...       0.000000     0.030672   \n",
       "201101019         0.053283      0.026765     ...       0.000000     0.023108   \n",
       "201101021         0.038276      0.026190     ...       0.000000     0.017738   \n",
       "201101023         0.013670      0.022814     ...       0.000000     0.042448   \n",
       "201101025         0.057882      0.025943     ...       0.000000     0.035595   \n",
       "201101027         0.027448      0.023715     ...       0.000000     0.037847   \n",
       "201101029         0.046739      0.022245     ...       0.000000     0.016804   \n",
       "201101031         0.039634      0.025593     ...       0.000000     0.046305   \n",
       "201101033         0.042827      0.024947     ...       0.000000     0.030892   \n",
       "201101035         0.022434      0.019102     ...       0.000000     0.020495   \n",
       "201101037         0.000000      0.031975     ...       0.000000     0.025432   \n",
       "201101039         0.041575      0.025803     ...       0.000000     0.020158   \n",
       "201101041         0.054814      0.029077     ...       0.000000     0.037194   \n",
       "201101043         0.050602      0.028201     ...       0.000000     0.030086   \n",
       "201101045         0.053812      0.025608     ...       0.000000     0.030631   \n",
       "201101047         0.045687      0.031765     ...       0.000000     0.022347   \n",
       "201101049         0.042874      0.024105     ...       0.000000     0.043489   \n",
       "201101051         0.042489      0.026909     ...       0.000000     0.020102   \n",
       "201101053         0.049286      0.027062     ...       0.000000     0.025270   \n",
       "201101055         0.033605      0.016283     ...       0.163261     0.021588   \n",
       "201101057         0.028677      0.021000     ...       0.000000     0.029077   \n",
       "201101059         0.039294      0.024484     ...       0.000000     0.022906   \n",
       "...                    ...           ...     ...            ...          ...   \n",
       "201655129         0.045589      0.025036     ...       0.021820     0.026003   \n",
       "201655131         0.047754      0.024611     ...       0.055777     0.032382   \n",
       "201655133         0.047971      0.024183     ...       0.040247     0.028654   \n",
       "201655135         0.056757      0.026939     ...       0.000000     0.024547   \n",
       "201655137         0.048901      0.021638     ...       0.000000     0.026143   \n",
       "201655139         0.043036      0.019420     ...       0.147481     0.021437   \n",
       "201655141         0.041534      0.024823     ...       0.000000     0.026631   \n",
       "201656001         0.017564      0.020737     ...       0.000000     0.022489   \n",
       "201656003         0.071590      0.021056     ...       0.000000     0.040292   \n",
       "201656005         0.046719      0.023117     ...       0.000000     0.025882   \n",
       "201656007         0.040324      0.029524     ...       0.000000     0.026376   \n",
       "201656009         0.041922      0.016037     ...       0.000000     0.016884   \n",
       "201656011         0.044255      0.024118     ...       0.000000     0.027258   \n",
       "201656013         0.040480      0.029197     ...       0.000000     0.027359   \n",
       "201656015         0.058460      0.024058     ...       0.000000     0.057113   \n",
       "201656017         0.094922      0.027728     ...       0.000000     0.023831   \n",
       "201656019         0.060360      0.031589     ...       0.000000     0.017333   \n",
       "201656021         0.048907      0.026209     ...       0.000000     0.025091   \n",
       "201656023         0.034827      0.025756     ...       0.000000     0.023534   \n",
       "201656025         0.049755      0.023743     ...       0.000000     0.032089   \n",
       "201656027         0.000000      0.029609     ...       0.000000     0.043930   \n",
       "201656029         0.048912      0.028088     ...       0.000000     0.032530   \n",
       "201656031         0.072222      0.024951     ...       0.000000     0.001624   \n",
       "201656033         0.042612      0.026719     ...       0.000000     0.023592   \n",
       "201656035         0.081627      0.017693     ...       0.000000     0.038561   \n",
       "201656037         0.039580      0.020456     ...       0.000000     0.022580   \n",
       "201656039         0.039649      0.020742     ...       0.000000     0.036911   \n",
       "201656041         0.049248      0.019468     ...       0.000000     0.013895   \n",
       "201656043         0.039863      0.025249     ...       0.000000     0.041048   \n",
       "201656045         0.075895      0.024612     ...       0.000000     0.042715   \n",
       "\n",
       "           total_edu_health_social_1  edu_serv_1  health_social_1  \\\n",
       "new_index                                                           \n",
       "201101001                   0.037950    0.042534         0.035264   \n",
       "201101003                   0.039780    0.044267         0.036876   \n",
       "201101005                   0.036902    0.068945         0.029141   \n",
       "201101007                   0.034044    0.046197         0.028691   \n",
       "201101009                   0.038854    0.047215         0.037251   \n",
       "201101011                   0.060968    0.073537         0.037080   \n",
       "201101013                   0.037109    0.036859         0.037142   \n",
       "201101015                   0.037686    0.044893         0.030489   \n",
       "201101017                   0.037197    0.056113         0.030398   \n",
       "201101019                   0.050116    0.065870         0.035170   \n",
       "201101021                   0.040842    0.048254         0.034679   \n",
       "201101023                   0.029092    0.028320         0.030249   \n",
       "201101025                   0.035887    0.037344         0.033919   \n",
       "201101027                   0.039196    0.048040         0.038975   \n",
       "201101029                   0.038755    0.045622         0.037847   \n",
       "201101031                   0.043382    0.055708         0.032983   \n",
       "201101033                   0.040485    0.050103         0.036449   \n",
       "201101035                   0.050744    0.072586         0.031211   \n",
       "201101037                   0.041093    0.047699         0.039474   \n",
       "201101039                   0.034648    0.049613         0.030926   \n",
       "201101041                   0.034407    0.034648         0.034347   \n",
       "201101043                   0.040432    0.045191         0.038170   \n",
       "201101045                   0.040993    0.049067         0.038533   \n",
       "201101047                   0.051120    0.058495         0.046544   \n",
       "201101049                   0.044823    0.058982         0.038299   \n",
       "201101051                   0.038639    0.042116         0.036711   \n",
       "201101053                   0.038714    0.059233         0.032452   \n",
       "201101055                   0.037364    0.041034         0.035996   \n",
       "201101057                   0.037220    0.058983         0.031115   \n",
       "201101059                   0.042038    0.061119         0.039140   \n",
       "...                              ...         ...              ...   \n",
       "201655129                   0.041028    0.047377         0.036955   \n",
       "201655131                   0.033700    0.034214         0.033470   \n",
       "201655133                   0.037317    0.038874         0.036825   \n",
       "201655135                   0.038673    0.047750         0.035620   \n",
       "201655137                   0.035199    0.042626         0.031572   \n",
       "201655139                   0.032002    0.036596         0.030703   \n",
       "201655141                   0.040181    0.051318         0.038525   \n",
       "201656001                   0.038051    0.041943         0.034573   \n",
       "201656003                   0.037047    0.036154         0.038228   \n",
       "201656005                   0.032964    0.039328         0.029283   \n",
       "201656007                   0.037813    0.042791         0.035710   \n",
       "201656009                   0.032970    0.034043         0.031671   \n",
       "201656011                   0.028069    0.039697         0.023639   \n",
       "201656013                   0.036498    0.046236         0.031492   \n",
       "201656015                   0.042448    0.054771         0.034530   \n",
       "201656017                   0.048175    0.048511         0.047456   \n",
       "201656019                   0.034055    0.050224         0.026496   \n",
       "201656021                   0.038115    0.045142         0.036603   \n",
       "201656023                   0.025743    0.021542         0.029857   \n",
       "201656025                   0.035244    0.039246         0.033037   \n",
       "201656027                   0.046802    0.049189         0.023879   \n",
       "201656029                   0.038926    0.052824         0.033536   \n",
       "201656031                   0.037820    0.047880         0.029547   \n",
       "201656033                   0.036214    0.045830         0.031365   \n",
       "201656035                   0.022860    0.035776         0.020007   \n",
       "201656037                   0.028337    0.027795         0.028603   \n",
       "201656039                   0.045390    0.036289         0.046339   \n",
       "201656041                   0.028079    0.026542         0.028564   \n",
       "201656043                   0.033592    0.057413         0.027478   \n",
       "201656045                   0.024543    0.024594         0.023474   \n",
       "\n",
       "           total_arts_ent_acc_food_1  arts_ent_rec_1  acc_food_serv_1  \\\n",
       "new_index                                                               \n",
       "201101001                   0.012536        0.013112         0.012443   \n",
       "201101003                   0.016616        0.029922         0.015958   \n",
       "201101005                   0.011919        0.013113         0.011421   \n",
       "201101007                   0.019591        0.004708         0.022744   \n",
       "201101009                   0.008756        0.007591         0.008822   \n",
       "201101011                   0.019706        0.073923         0.016272   \n",
       "201101013                   0.010408        0.032644         0.010307   \n",
       "201101015                   0.012747        0.010288         0.012960   \n",
       "201101017                   0.015714        0.104354         0.015117   \n",
       "201101019                   0.008778        0.011615         0.008582   \n",
       "201101021                   0.013361        0.026181         0.013099   \n",
       "201101023                   0.016224        0.000000         0.016697   \n",
       "201101025                   0.014347        0.050047         0.013758   \n",
       "201101027                   0.014715        0.016998         0.013564   \n",
       "201101029                   0.014451        0.001858         0.015021   \n",
       "201101031                   0.014923        0.026643         0.014357   \n",
       "201101033                   0.018186        0.017150         0.018553   \n",
       "201101035                   0.005070        0.000000         0.005070   \n",
       "201101037                   0.021597        0.048861         0.021112   \n",
       "201101039                   0.016806        0.015819         0.017069   \n",
       "201101041                   0.013392        0.037784         0.012431   \n",
       "201101043                   0.011805        0.010767         0.011818   \n",
       "201101045                   0.015440        0.014812         0.015547   \n",
       "201101047                   0.014631        0.012204         0.014932   \n",
       "201101049                   0.015440        0.009435         0.016886   \n",
       "201101051                   0.018574        0.024048         0.014165   \n",
       "201101053                   0.019154        0.027009         0.015783   \n",
       "201101055                   0.015083        0.018985         0.014655   \n",
       "201101057                   0.009795        0.058146         0.009465   \n",
       "201101059                   0.018320        0.022901         0.017773   \n",
       "...                              ...             ...              ...   \n",
       "201655129                   0.012232        0.024568         0.010556   \n",
       "201655131                   0.009819        0.009074         0.009887   \n",
       "201655133                   0.009776        0.011545         0.009250   \n",
       "201655135                   0.011495        0.009250         0.011845   \n",
       "201655137                   0.012869        0.020054         0.012067   \n",
       "201655139                   0.010396        0.011523         0.010238   \n",
       "201655141                   0.014506        0.018237         0.013639   \n",
       "201656001                   0.014355        0.010686         0.015282   \n",
       "201656003                   0.009245        0.007377         0.009968   \n",
       "201656005                   0.010110        0.009187         0.010217   \n",
       "201656007                   0.016598        0.005851         0.017700   \n",
       "201656009                   0.015754        0.001575         0.016429   \n",
       "201656011                   0.018581        0.018263         0.018848   \n",
       "201656013                   0.020714        0.027137         0.014369   \n",
       "201656015                   0.014521        0.016976         0.014018   \n",
       "201656017                   0.012355        0.016317         0.011094   \n",
       "201656019                   0.006651        0.001246         0.007265   \n",
       "201656021                   0.016366        0.023213         0.015849   \n",
       "201656023                   0.013860        0.020972         0.010693   \n",
       "201656025                   0.017659        0.026087         0.017372   \n",
       "201656027                   0.012674        0.000000         0.014052   \n",
       "201656029                   0.011079        0.029926         0.008101   \n",
       "201656031                   0.011083        0.030254         0.009815   \n",
       "201656033                   0.014974        0.030403         0.013958   \n",
       "201656035                   0.009760        0.028070         0.006863   \n",
       "201656037                   0.013421        0.017545         0.012761   \n",
       "201656039                   0.023790        0.033171         0.022171   \n",
       "201656041                   0.008382        0.005728         0.009293   \n",
       "201656043                   0.011332        0.009073         0.012138   \n",
       "201656045                   0.021031        0.035306         0.015407   \n",
       "\n",
       "           other_ser_1  pub_admin_1  \n",
       "new_index                            \n",
       "201101001     0.032354     0.060475  \n",
       "201101003     0.024313     0.043733  \n",
       "201101005     0.025411     0.052426  \n",
       "201101007     0.027503     0.041305  \n",
       "201101009     0.029518     0.044929  \n",
       "201101011     0.070545     0.066220  \n",
       "201101013     0.022408     0.045637  \n",
       "201101015     0.022508     0.060025  \n",
       "201101017     0.025457     0.049391  \n",
       "201101019     0.019458     0.054200  \n",
       "201101021     0.028777     0.052831  \n",
       "201101023     0.029996     0.040801  \n",
       "201101025     0.015537     0.039260  \n",
       "201101027     0.038888     0.046093  \n",
       "201101029     0.040023     0.053626  \n",
       "201101031     0.028947     0.065745  \n",
       "201101033     0.042354     0.041571  \n",
       "201101035     0.037015     0.050686  \n",
       "201101037     0.019234     0.069338  \n",
       "201101039     0.028721     0.042183  \n",
       "201101041     0.037548     0.050584  \n",
       "201101043     0.026283     0.050447  \n",
       "201101045     0.022673     0.063236  \n",
       "201101047     0.029454     0.059994  \n",
       "201101049     0.024305     0.045895  \n",
       "201101051     0.027585     0.058108  \n",
       "201101053     0.032507     0.046644  \n",
       "201101055     0.023689     0.050626  \n",
       "201101057     0.031448     0.052229  \n",
       "201101059     0.035875     0.053188  \n",
       "...                ...          ...  \n",
       "201655129     0.023730     0.052563  \n",
       "201655131     0.028379     0.055685  \n",
       "201655133     0.023636     0.048317  \n",
       "201655135     0.028748     0.050309  \n",
       "201655137     0.033565     0.049673  \n",
       "201655139     0.025702     0.047213  \n",
       "201655141     0.027096     0.061870  \n",
       "201656001     0.022531     0.064585  \n",
       "201656003     0.042665     0.048249  \n",
       "201656005     0.036700     0.048728  \n",
       "201656007     0.037850     0.048674  \n",
       "201656009     0.024635     0.048932  \n",
       "201656011     0.022071     0.050690  \n",
       "201656013     0.025353     0.050301  \n",
       "201656015     0.035633     0.050975  \n",
       "201656017     0.014491     0.050949  \n",
       "201656019     0.014363     0.044630  \n",
       "201656021     0.026538     0.051785  \n",
       "201656023     0.025856     0.047571  \n",
       "201656025     0.031176     0.051020  \n",
       "201656027     0.000000     0.055472  \n",
       "201656029     0.023187     0.054524  \n",
       "201656031     0.058710     0.029459  \n",
       "201656033     0.026908     0.043996  \n",
       "201656035     0.032854     0.053497  \n",
       "201656037     0.028321     0.049015  \n",
       "201656039     0.021480     0.035484  \n",
       "201656041     0.031530     0.044609  \n",
       "201656043     0.025729     0.052542  \n",
       "201656045     0.024191     0.042459  \n",
       "\n",
       "[18853 rows x 57 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = pd.concat([result2,result], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_agri_fish_mine</th>\n",
       "      <th>agri_fish_hunt</th>\n",
       "      <th>mining_quarrying_oilgas_extract</th>\n",
       "      <th>construction</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>wholesale_trade</th>\n",
       "      <th>retail_trade</th>\n",
       "      <th>...</th>\n",
       "      <th>wholesale_trade_1</th>\n",
       "      <th>retail_trade_1</th>\n",
       "      <th>transport_utilities_1</th>\n",
       "      <th>information_1</th>\n",
       "      <th>finance_insurance_realestate_1</th>\n",
       "      <th>prof_scientific_waste_1</th>\n",
       "      <th>edu_health_1</th>\n",
       "      <th>arts_recreation_1</th>\n",
       "      <th>other_1</th>\n",
       "      <th>public_admin_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01003</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.093891</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>0.143542</td>\n",
       "      <td>0.050436</td>\n",
       "      <td>0.014955</td>\n",
       "      <td>0.059526</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.221214</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.048301</td>\n",
       "      <td>0.036560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101015</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>01015</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>0.032316</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.046204</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.117222</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.097882</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.081013</td>\n",
       "      <td>0.051918</td>\n",
       "      <td>0.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101043</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>01043</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.030104</td>\n",
       "      <td>0.059925</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101049</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>01049</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.030962</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.042874</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.135833</td>\n",
       "      <td>0.054265</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>0.080747</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.042632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101051</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>01051</td>\n",
       "      <td>0.030874</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>0.038913</td>\n",
       "      <td>0.043618</td>\n",
       "      <td>0.042489</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101055</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>01055</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>0.046870</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>0.113706</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.045908</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>0.113808</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>0.062973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101069</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>01069</td>\n",
       "      <td>0.033606</td>\n",
       "      <td>0.030472</td>\n",
       "      <td>0.090438</td>\n",
       "      <td>0.033025</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>0.022233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044390</td>\n",
       "      <td>0.119499</td>\n",
       "      <td>0.096198</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.038269</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.225213</td>\n",
       "      <td>0.090322</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.051472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101073</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>01073</td>\n",
       "      <td>0.047683</td>\n",
       "      <td>0.029139</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.041644</td>\n",
       "      <td>0.042646</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>0.101286</td>\n",
       "      <td>0.053590</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>0.116549</td>\n",
       "      <td>0.272641</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.044486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101077</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>01077</td>\n",
       "      <td>0.036483</td>\n",
       "      <td>0.035629</td>\n",
       "      <td>0.047185</td>\n",
       "      <td>0.035607</td>\n",
       "      <td>0.050738</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101081</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>01081</td>\n",
       "      <td>0.041571</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>0.068927</td>\n",
       "      <td>0.033677</td>\n",
       "      <td>0.048705</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>0.024549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.128486</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.040722</td>\n",
       "      <td>0.076828</td>\n",
       "      <td>0.288127</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.039910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101083</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>01083</td>\n",
       "      <td>0.024578</td>\n",
       "      <td>0.024578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.049389</td>\n",
       "      <td>0.040575</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101089</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>01089</td>\n",
       "      <td>0.033374</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.056012</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>0.045398</td>\n",
       "      <td>0.047406</td>\n",
       "      <td>0.019938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.117546</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>0.179244</td>\n",
       "      <td>0.081932</td>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.087763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101095</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>01095</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.030412</td>\n",
       "      <td>0.065535</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>0.049028</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>0.114291</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.036929</td>\n",
       "      <td>0.062762</td>\n",
       "      <td>0.198167</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.043829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101097</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>01097</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>0.023725</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.039045</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.046372</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>0.139225</td>\n",
       "      <td>0.054112</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.056813</td>\n",
       "      <td>0.097774</td>\n",
       "      <td>0.233898</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>0.059638</td>\n",
       "      <td>0.039582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101101</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>01101</td>\n",
       "      <td>0.032343</td>\n",
       "      <td>0.031135</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.022759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.216640</td>\n",
       "      <td>0.102690</td>\n",
       "      <td>0.057959</td>\n",
       "      <td>0.119482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101103</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>01103</td>\n",
       "      <td>0.031286</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.064539</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.040942</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.125086</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>0.075295</td>\n",
       "      <td>0.059207</td>\n",
       "      <td>0.033121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101115</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>01115</td>\n",
       "      <td>0.042739</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>0.060669</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>0.044868</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.024809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101117</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>01117</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.044673</td>\n",
       "      <td>0.042593</td>\n",
       "      <td>0.022515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.114391</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>0.197602</td>\n",
       "      <td>0.061784</td>\n",
       "      <td>0.059296</td>\n",
       "      <td>0.046985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101121</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>01121</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.023794</td>\n",
       "      <td>0.045583</td>\n",
       "      <td>0.039483</td>\n",
       "      <td>0.056733</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.028079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101125</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>01125</td>\n",
       "      <td>0.063266</td>\n",
       "      <td>0.036771</td>\n",
       "      <td>0.068630</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.042180</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.034689</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.054224</td>\n",
       "      <td>0.067698</td>\n",
       "      <td>0.284911</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.042211</td>\n",
       "      <td>0.048357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101127</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>01127</td>\n",
       "      <td>0.066049</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.066619</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.043018</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102020</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>02020</td>\n",
       "      <td>0.069295</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>0.072182</td>\n",
       "      <td>0.039226</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>0.020968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030751</td>\n",
       "      <td>0.117070</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.110399</td>\n",
       "      <td>0.249707</td>\n",
       "      <td>0.100512</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.111625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102090</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>02090</td>\n",
       "      <td>0.065184</td>\n",
       "      <td>0.057787</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.045598</td>\n",
       "      <td>0.046985</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.023174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.142124</td>\n",
       "      <td>0.072324</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.036130</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.217588</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>0.049263</td>\n",
       "      <td>0.150334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102170</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>02170</td>\n",
       "      <td>0.065438</td>\n",
       "      <td>0.014903</td>\n",
       "      <td>0.075126</td>\n",
       "      <td>0.041848</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.107263</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.020109</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.251476</td>\n",
       "      <td>0.078537</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>0.083070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104001</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>04001</td>\n",
       "      <td>0.048935</td>\n",
       "      <td>0.035760</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.043754</td>\n",
       "      <td>0.032726</td>\n",
       "      <td>0.026974</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104003</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>04003</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>0.048229</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.050587</td>\n",
       "      <td>0.033322</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104005</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>04005</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.098503</td>\n",
       "      <td>0.035747</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.126760</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>0.071978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104013</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>04013</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.057680</td>\n",
       "      <td>0.035279</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>0.043933</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.120632</td>\n",
       "      <td>0.051141</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.099774</td>\n",
       "      <td>0.130022</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.046061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104015</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>04015</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.040951</td>\n",
       "      <td>0.048452</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.047142</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.130677</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>0.052163</td>\n",
       "      <td>0.076398</td>\n",
       "      <td>0.189562</td>\n",
       "      <td>0.174207</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201104017</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>04017</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>0.043211</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>0.026275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654033</th>\n",
       "      <td>18719</td>\n",
       "      <td>18719</td>\n",
       "      <td>54033</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>0.053144</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.040709</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.118177</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.296526</td>\n",
       "      <td>0.085022</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>0.115786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654039</th>\n",
       "      <td>18722</td>\n",
       "      <td>18722</td>\n",
       "      <td>54039</td>\n",
       "      <td>0.065192</td>\n",
       "      <td>0.021054</td>\n",
       "      <td>0.066869</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.079815</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.065889</td>\n",
       "      <td>0.100224</td>\n",
       "      <td>0.270667</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654061</th>\n",
       "      <td>18733</td>\n",
       "      <td>18733</td>\n",
       "      <td>54061</td>\n",
       "      <td>0.070675</td>\n",
       "      <td>0.034348</td>\n",
       "      <td>0.072753</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>0.061884</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.121354</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.059201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654081</th>\n",
       "      <td>18743</td>\n",
       "      <td>18743</td>\n",
       "      <td>54081</td>\n",
       "      <td>0.083178</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>0.085379</td>\n",
       "      <td>0.038580</td>\n",
       "      <td>0.046436</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025861</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.238304</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.049026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654107</th>\n",
       "      <td>18756</td>\n",
       "      <td>18756</td>\n",
       "      <td>54107</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.049369</td>\n",
       "      <td>0.059183</td>\n",
       "      <td>0.036634</td>\n",
       "      <td>0.059202</td>\n",
       "      <td>0.052677</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.131056</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.320483</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.089474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655009</th>\n",
       "      <td>18762</td>\n",
       "      <td>18762</td>\n",
       "      <td>55009</td>\n",
       "      <td>0.027547</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.063987</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.043561</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031923</td>\n",
       "      <td>0.105683</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>0.084382</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>0.093170</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>0.020846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655025</th>\n",
       "      <td>18770</td>\n",
       "      <td>18770</td>\n",
       "      <td>55025</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.028114</td>\n",
       "      <td>0.036904</td>\n",
       "      <td>0.045140</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.100363</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.082944</td>\n",
       "      <td>0.137849</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>0.090658</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655027</th>\n",
       "      <td>18771</td>\n",
       "      <td>18771</td>\n",
       "      <td>55027</td>\n",
       "      <td>0.026795</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.185140</td>\n",
       "      <td>0.063427</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>0.030040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655035</th>\n",
       "      <td>18775</td>\n",
       "      <td>18775</td>\n",
       "      <td>55035</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.126234</td>\n",
       "      <td>0.037685</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.193205</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.059241</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.267207</td>\n",
       "      <td>0.079175</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.033937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655039</th>\n",
       "      <td>18777</td>\n",
       "      <td>18777</td>\n",
       "      <td>55039</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.050728</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>0.209634</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.045790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655055</th>\n",
       "      <td>18785</td>\n",
       "      <td>18785</td>\n",
       "      <td>55055</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.045018</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.238870</td>\n",
       "      <td>0.077360</td>\n",
       "      <td>0.043771</td>\n",
       "      <td>0.026514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655059</th>\n",
       "      <td>18787</td>\n",
       "      <td>18787</td>\n",
       "      <td>55059</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.169675</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.085926</td>\n",
       "      <td>0.225782</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655063</th>\n",
       "      <td>18789</td>\n",
       "      <td>18789</td>\n",
       "      <td>55063</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.044189</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>0.127378</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.032632</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>0.298961</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.032293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655071</th>\n",
       "      <td>18793</td>\n",
       "      <td>18793</td>\n",
       "      <td>55071</td>\n",
       "      <td>0.034781</td>\n",
       "      <td>0.033315</td>\n",
       "      <td>0.054173</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>0.047011</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.092097</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.020994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655073</th>\n",
       "      <td>18794</td>\n",
       "      <td>18794</td>\n",
       "      <td>55073</td>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.027021</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.046943</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>0.023274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.109750</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>0.067402</td>\n",
       "      <td>0.227370</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.027045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655079</th>\n",
       "      <td>18798</td>\n",
       "      <td>18798</td>\n",
       "      <td>55079</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.027144</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>0.039166</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>0.044644</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.110877</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.061934</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.258274</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655087</th>\n",
       "      <td>18802</td>\n",
       "      <td>18802</td>\n",
       "      <td>55087</td>\n",
       "      <td>0.027341</td>\n",
       "      <td>0.027674</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.046574</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>0.090829</td>\n",
       "      <td>0.207668</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.027592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655089</th>\n",
       "      <td>18803</td>\n",
       "      <td>18803</td>\n",
       "      <td>55089</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.041052</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.109572</td>\n",
       "      <td>0.037420</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.108895</td>\n",
       "      <td>0.233125</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.033925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655097</th>\n",
       "      <td>18807</td>\n",
       "      <td>18807</td>\n",
       "      <td>55097</td>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.030192</td>\n",
       "      <td>0.064455</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.047595</td>\n",
       "      <td>0.044847</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.125702</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.027890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655101</th>\n",
       "      <td>18809</td>\n",
       "      <td>18809</td>\n",
       "      <td>55101</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.048088</td>\n",
       "      <td>0.047008</td>\n",
       "      <td>0.023239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>0.086634</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.076496</td>\n",
       "      <td>0.040780</td>\n",
       "      <td>0.032095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655105</th>\n",
       "      <td>18811</td>\n",
       "      <td>18811</td>\n",
       "      <td>55105</td>\n",
       "      <td>0.032364</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.108631</td>\n",
       "      <td>0.044023</td>\n",
       "      <td>0.042340</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033063</td>\n",
       "      <td>0.115378</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.066037</td>\n",
       "      <td>0.212013</td>\n",
       "      <td>0.071704</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.029149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655109</th>\n",
       "      <td>18813</td>\n",
       "      <td>18813</td>\n",
       "      <td>55109</td>\n",
       "      <td>0.019602</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.036892</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>0.046837</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>0.023498</td>\n",
       "      <td>0.069111</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>0.070616</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.037007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655117</th>\n",
       "      <td>18817</td>\n",
       "      <td>18817</td>\n",
       "      <td>55117</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.037738</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.049222</td>\n",
       "      <td>0.052010</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.028649</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.067037</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.185135</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.025314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655127</th>\n",
       "      <td>18822</td>\n",
       "      <td>18822</td>\n",
       "      <td>55127</td>\n",
       "      <td>0.029304</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>0.028732</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.046045</td>\n",
       "      <td>0.052204</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>0.134970</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>0.225702</td>\n",
       "      <td>0.106738</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.025108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655131</th>\n",
       "      <td>18824</td>\n",
       "      <td>18824</td>\n",
       "      <td>55131</td>\n",
       "      <td>0.033418</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.052911</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.047754</td>\n",
       "      <td>0.024611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.095768</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.015786</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>0.207379</td>\n",
       "      <td>0.075402</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>0.037876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655133</th>\n",
       "      <td>18825</td>\n",
       "      <td>18825</td>\n",
       "      <td>55133</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.070681</td>\n",
       "      <td>0.043071</td>\n",
       "      <td>0.049311</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042637</td>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.082146</td>\n",
       "      <td>0.110605</td>\n",
       "      <td>0.223792</td>\n",
       "      <td>0.076854</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.027043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655139</th>\n",
       "      <td>18828</td>\n",
       "      <td>18828</td>\n",
       "      <td>55139</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>0.049006</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.043036</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>0.199925</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>0.024915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655141</th>\n",
       "      <td>18829</td>\n",
       "      <td>18829</td>\n",
       "      <td>55141</td>\n",
       "      <td>0.039303</td>\n",
       "      <td>0.039496</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021737</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.067083</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>0.043448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656021</th>\n",
       "      <td>18840</td>\n",
       "      <td>18840</td>\n",
       "      <td>56021</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.061011</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.026209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.061820</td>\n",
       "      <td>0.033988</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.259028</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>0.059652</td>\n",
       "      <td>0.127411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201656025</th>\n",
       "      <td>18842</td>\n",
       "      <td>18842</td>\n",
       "      <td>56025</td>\n",
       "      <td>0.063043</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.068105</td>\n",
       "      <td>0.041928</td>\n",
       "      <td>0.042170</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.074406</td>\n",
       "      <td>0.262701</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.036316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4884 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  index   fips  total_agri_fish_mine  agri_fish_hunt  \\\n",
       "new_index                                                                   \n",
       "201101003           1      1  01003              0.038482        0.031718   \n",
       "201101015           7      7  01015              0.032432        0.032480   \n",
       "201101043          21     21  01043              0.039981        0.030104   \n",
       "201101049          24     24  01049              0.032573        0.030864   \n",
       "201101051          25     25  01051              0.030874        0.030562   \n",
       "201101055          27     27  01055              0.016638        0.016438   \n",
       "201101069          34     34  01069              0.033606        0.030472   \n",
       "201101073          36     36  01073              0.047683        0.029139   \n",
       "201101077          38     38  01077              0.036483        0.035629   \n",
       "201101081          40     40  01081              0.041571        0.034519   \n",
       "201101083          41     41  01083              0.024578        0.024578   \n",
       "201101089          44     44  01089              0.033374        0.022700   \n",
       "201101095          47     47  01095              0.030673        0.030412   \n",
       "201101097          48     48  01097              0.038287        0.023725   \n",
       "201101101          50     50  01101              0.032343        0.031135   \n",
       "201101103          51     51  01103              0.031286        0.030693   \n",
       "201101115          57     57  01115              0.042739        0.013981   \n",
       "201101117          58     58  01117              0.051148        0.026774   \n",
       "201101121          60     60  01121              0.029470        0.023794   \n",
       "201101125          62     62  01125              0.063266        0.036771   \n",
       "201101127          63     63  01127              0.066049        0.049731   \n",
       "201102020          69     69  02020              0.069295        0.042628   \n",
       "201102090          74     74  02090              0.065184        0.057787   \n",
       "201102170          82     82  02170              0.065438        0.014903   \n",
       "201104001          96     96  04001              0.048935        0.035760   \n",
       "201104003          97     97  04003              0.030246        0.026684   \n",
       "201104005          98     98  04005              0.047562        0.038194   \n",
       "201104013         103    103  04013              0.031651        0.023738   \n",
       "201104015         104    104  04015              0.045208        0.040951   \n",
       "201104017         105    105  04017              0.042311        0.032638   \n",
       "...               ...    ...    ...                   ...             ...   \n",
       "201654033       18719  18719  54033              0.052059        0.020776   \n",
       "201654039       18722  18722  54039              0.065192        0.021054   \n",
       "201654061       18733  18733  54061              0.070675        0.034348   \n",
       "201654081       18743  18743  54081              0.083178        0.018873   \n",
       "201654107       18756  18756  54107              0.058710        0.049369   \n",
       "201655009       18762  18762  55009              0.027547        0.026961   \n",
       "201655025       18770  18770  55025              0.028217        0.028114   \n",
       "201655027       18771  18771  55027              0.026795        0.025934   \n",
       "201655035       18775  18775  55035              0.025389        0.023458   \n",
       "201655039       18777  18777  55039              0.032852        0.031033   \n",
       "201655055       18785  18785  55055              0.029166        0.028851   \n",
       "201655059       18787  18787  55059              0.026700        0.025640   \n",
       "201655063       18789  18789  55063              0.024941        0.023626   \n",
       "201655071       18793  18793  55071              0.034781        0.033315   \n",
       "201655073       18794  18794  55073              0.027478        0.027021   \n",
       "201655079       18798  18798  55079              0.028600        0.027144   \n",
       "201655087       18802  18802  55087              0.027341        0.027674   \n",
       "201655089       18803  18803  55089              0.016809        0.016503   \n",
       "201655097       18807  18807  55097              0.031166        0.030192   \n",
       "201655101       18809  18809  55101              0.026240        0.024256   \n",
       "201655105       18811  18811  55105              0.032364        0.030649   \n",
       "201655109       18813  18813  55109              0.019602        0.018930   \n",
       "201655117       18817  18817  55117              0.032387        0.032009   \n",
       "201655127       18822  18822  55127              0.029304        0.029493   \n",
       "201655131       18824  18824  55131              0.033418        0.031374   \n",
       "201655133       18825  18825  55133              0.025591        0.022200   \n",
       "201655139       18828  18828  55139              0.030307        0.029802   \n",
       "201655141       18829  18829  55141              0.039303        0.039496   \n",
       "201656021       18840  18840  56021              0.053369        0.031811   \n",
       "201656025       18842  18842  56025              0.063043        0.020677   \n",
       "\n",
       "           mining_quarrying_oilgas_extract  construction  manufacturing  \\\n",
       "new_index                                                                 \n",
       "201101003                         0.093891      0.034880       0.048625   \n",
       "201101015                         0.032316      0.037765       0.048511   \n",
       "201101043                         0.059925      0.032815       0.040207   \n",
       "201101049                         0.074730      0.030962       0.036114   \n",
       "201101051                         0.044875      0.038913       0.043618   \n",
       "201101055                         0.046870      0.025226       0.032633   \n",
       "201101069                         0.090438      0.033025       0.035853   \n",
       "201101073                         0.059640      0.032814       0.041644   \n",
       "201101077                         0.047185      0.035607       0.050738   \n",
       "201101081                         0.068927      0.033677       0.048705   \n",
       "201101083                         0.000000      0.032660       0.049389   \n",
       "201101089                         0.056012      0.029240       0.045398   \n",
       "201101095                         0.065535      0.027754       0.039247   \n",
       "201101097                         0.072034      0.039045       0.051777   \n",
       "201101101                         0.056637      0.032869       0.040628   \n",
       "201101103                         0.064539      0.028306       0.045387   \n",
       "201101115                         0.060669      0.035103       0.044868   \n",
       "201101117                         0.052856      0.030142       0.044673   \n",
       "201101121                         0.045583      0.039483       0.056733   \n",
       "201101125                         0.068630      0.032815       0.050059   \n",
       "201101127                         0.066619      0.033574       0.043018   \n",
       "201102020                         0.072182      0.039226       0.036803   \n",
       "201102090                         0.066575      0.045598       0.046985   \n",
       "201102170                         0.075126      0.041848       0.032957   \n",
       "201104001                         0.059244      0.043754       0.032726   \n",
       "201104003                         0.048229      0.036692       0.050587   \n",
       "201104005                         0.098503      0.035747       0.041499   \n",
       "201104013                         0.057680      0.035279       0.048518   \n",
       "201104015                         0.048452      0.035520       0.037882   \n",
       "201104017                         0.081467      0.043030       0.043211   \n",
       "...                                    ...           ...            ...   \n",
       "201654033                         0.053144      0.035620       0.060067   \n",
       "201654039                         0.066869      0.036992       0.048076   \n",
       "201654061                         0.072753      0.046747       0.061884   \n",
       "201654081                         0.085379      0.038580       0.046436   \n",
       "201654107                         0.059183      0.036634       0.059202   \n",
       "201655009                         0.063987      0.042343       0.043561   \n",
       "201655025                         0.036904      0.045140       0.044259   \n",
       "201655027                         0.040963      0.049775       0.045017   \n",
       "201655035                         0.126234      0.037685       0.043461   \n",
       "201655039                         0.039375      0.055944       0.050728   \n",
       "201655055                         0.045018      0.047836       0.044370   \n",
       "201655059                         0.031239      0.048009       0.048374   \n",
       "201655063                         0.077635      0.044189       0.042173   \n",
       "201655071                         0.054173      0.044268       0.047011   \n",
       "201655073                         0.038863      0.046943       0.044593   \n",
       "201655079                         0.040799      0.039166       0.044735   \n",
       "201655087                         0.015093      0.046574       0.052433   \n",
       "201655089                         0.055398      0.041052       0.046083   \n",
       "201655097                         0.064455      0.050368       0.047595   \n",
       "201655101                         0.061202      0.043799       0.048088   \n",
       "201655105                         0.108631      0.044023       0.042340   \n",
       "201655109                         0.128932      0.036892       0.042873   \n",
       "201655117                         0.037738      0.048351       0.049222   \n",
       "201655127                         0.028732      0.048606       0.046045   \n",
       "201655131                         0.052911      0.043691       0.046476   \n",
       "201655133                         0.070681      0.043071       0.049311   \n",
       "201655139                         0.049006      0.042554       0.045391   \n",
       "201655141                         0.017998      0.053359       0.054011   \n",
       "201656021                         0.061011      0.039187       0.052240   \n",
       "201656025                         0.068105      0.041928       0.042170   \n",
       "\n",
       "           wholesale_trade  retail_trade       ...        wholesale_trade_1  \\\n",
       "new_index                                      ...                            \n",
       "201101003         0.050396      0.024145       ...                 0.029687   \n",
       "201101015         0.046204      0.028544       ...                 0.014505   \n",
       "201101043         0.050602      0.028201       ...                 0.027073   \n",
       "201101049         0.042874      0.024105       ...                 0.029322   \n",
       "201101051         0.042489      0.026909       ...                 0.027073   \n",
       "201101055         0.033605      0.016283       ...                 0.041238   \n",
       "201101069         0.038347      0.022233       ...                 0.044390   \n",
       "201101073         0.042646      0.023366       ...                 0.029361   \n",
       "201101077         0.048622      0.024027       ...                 0.027073   \n",
       "201101081         0.052521      0.024549       ...                 0.011605   \n",
       "201101083         0.040575      0.024431       ...                 0.027073   \n",
       "201101089         0.047406      0.019938       ...                 0.015692   \n",
       "201101095         0.049028      0.026292       ...                 0.022522   \n",
       "201101097         0.046372      0.023372       ...                 0.031880   \n",
       "201101101         0.042945      0.022759       ...                 0.024690   \n",
       "201101103         0.040942      0.023603       ...                 0.023668   \n",
       "201101115         0.040890      0.024809       ...                 0.027073   \n",
       "201101117         0.042593      0.022515       ...                 0.034675   \n",
       "201101121         0.044778      0.028079       ...                 0.027073   \n",
       "201101125         0.042180      0.022223       ...                 0.022688   \n",
       "201101127         0.046931      0.021614       ...                 0.027073   \n",
       "201102020         0.037734      0.020968       ...                 0.030751   \n",
       "201102090         0.039863      0.023174       ...                 0.009886   \n",
       "201102170         0.050984      0.024114       ...                 0.016445   \n",
       "201104001         0.026974      0.022843       ...                 0.027073   \n",
       "201104003         0.033322      0.023440       ...                 0.027073   \n",
       "201104005         0.054684      0.025654       ...                 0.013723   \n",
       "201104013         0.043933      0.025686       ...                 0.028882   \n",
       "201104015         0.047142      0.026254       ...                 0.011893   \n",
       "201104017         0.044571      0.026275       ...                 0.027073   \n",
       "...                    ...           ...       ...                      ...   \n",
       "201654033         0.040709      0.021352       ...                 0.022976   \n",
       "201654039         0.050153      0.019401       ...                 0.023300   \n",
       "201654061         0.042841      0.018106       ...                 0.021541   \n",
       "201654081         0.048689      0.025055       ...                 0.025861   \n",
       "201654107         0.052677      0.020274       ...                 0.014593   \n",
       "201655009         0.047191      0.019604       ...                 0.031923   \n",
       "201655025         0.047057      0.023567       ...                 0.017753   \n",
       "201655027         0.040873      0.023659       ...                 0.020326   \n",
       "201655035         0.045257      0.025309       ...                 0.027088   \n",
       "201655039         0.050300      0.028361       ...                 0.022365   \n",
       "201655055         0.046476      0.023603       ...                 0.016530   \n",
       "201655059         0.043799      0.022430       ...                 0.033557   \n",
       "201655063         0.049511      0.024962       ...                 0.029254   \n",
       "201655071         0.042103      0.020053       ...                 0.013362   \n",
       "201655073         0.044361      0.023274       ...                 0.041016   \n",
       "201655079         0.044644      0.022630       ...                 0.027123   \n",
       "201655087         0.048134      0.020997       ...                 0.033813   \n",
       "201655089         0.056247      0.016178       ...                 0.030211   \n",
       "201655097         0.044847      0.021116       ...                 0.015865   \n",
       "201655101         0.047008      0.023239       ...                 0.029709   \n",
       "201655105         0.038137      0.023337       ...                 0.033063   \n",
       "201655109         0.046837      0.021492       ...                 0.023844   \n",
       "201655117         0.052010      0.024143       ...                 0.017259   \n",
       "201655127         0.052204      0.023123       ...                 0.032571   \n",
       "201655131         0.047754      0.024611       ...                 0.025311   \n",
       "201655133         0.047971      0.024183       ...                 0.042637   \n",
       "201655139         0.043036      0.019420       ...                 0.033121   \n",
       "201655141         0.041534      0.024823       ...                 0.021737   \n",
       "201656021         0.048907      0.026209       ...                 0.009039   \n",
       "201656025         0.049755      0.023743       ...                 0.034181   \n",
       "\n",
       "           retail_trade_1  transport_utilities_1  information_1  \\\n",
       "new_index                                                         \n",
       "201101003        0.143542               0.050436       0.014955   \n",
       "201101015        0.117222               0.037962       0.020691   \n",
       "201101043        0.119457               0.048909       0.019094   \n",
       "201101049        0.135833               0.054265       0.014610   \n",
       "201101051        0.119457               0.048909       0.019094   \n",
       "201101055        0.113706               0.052478       0.008981   \n",
       "201101069        0.119499               0.096198       0.014208   \n",
       "201101073        0.101286               0.053590       0.021607   \n",
       "201101077        0.119457               0.048909       0.019094   \n",
       "201101081        0.128486               0.025439       0.017798   \n",
       "201101083        0.119457               0.048909       0.019094   \n",
       "201101089        0.117546               0.034726       0.030083   \n",
       "201101095        0.114291               0.039551       0.013772   \n",
       "201101097        0.139225               0.054112       0.013870   \n",
       "201101101        0.134467               0.028985       0.011178   \n",
       "201101103        0.125086               0.029213       0.018433   \n",
       "201101115        0.119457               0.048909       0.019094   \n",
       "201101117        0.114391               0.037506       0.029285   \n",
       "201101121        0.119457               0.048909       0.019094   \n",
       "201101125        0.113499               0.034689       0.015433   \n",
       "201101127        0.119457               0.048909       0.019094   \n",
       "201102020        0.117070               0.062956       0.020289   \n",
       "201102090        0.142124               0.072324       0.007935   \n",
       "201102170        0.107263               0.091003       0.020109   \n",
       "201104001        0.119457               0.048909       0.019094   \n",
       "201104003        0.119457               0.048909       0.019094   \n",
       "201104005        0.126760               0.046931       0.007601   \n",
       "201104013        0.120632               0.051141       0.019078   \n",
       "201104015        0.130677               0.071125       0.026495   \n",
       "201104017        0.119457               0.048909       0.019094   \n",
       "...                   ...                    ...            ...   \n",
       "201654033        0.118177               0.050671       0.008854   \n",
       "201654039        0.079815               0.042872       0.029697   \n",
       "201654061        0.073314               0.044547       0.007930   \n",
       "201654081        0.119262               0.050540       0.017906   \n",
       "201654107        0.131056               0.013842       0.015399   \n",
       "201655009        0.105683               0.059434       0.013720   \n",
       "201655025        0.100363               0.028759       0.027053   \n",
       "201655027        0.105413               0.047324       0.012690   \n",
       "201655035        0.193205               0.051113       0.012940   \n",
       "201655039        0.103813               0.056220       0.019669   \n",
       "201655055        0.118884               0.041942       0.011990   \n",
       "201655059        0.169675               0.056785       0.010555   \n",
       "201655063        0.127378               0.042912       0.032632   \n",
       "201655071        0.092097               0.060837       0.008315   \n",
       "201655073        0.109750               0.035602       0.006382   \n",
       "201655079        0.110877               0.047110       0.017094   \n",
       "201655087        0.127579               0.036342       0.008640   \n",
       "201655089        0.109572               0.037420       0.012823   \n",
       "201655097        0.125702               0.051065       0.008131   \n",
       "201655101        0.125592               0.061490       0.013684   \n",
       "201655105        0.115378               0.038247       0.026341   \n",
       "201655109        0.096718               0.052042       0.023498   \n",
       "201655117        0.113262               0.028649       0.010139   \n",
       "201655127        0.134970               0.034615       0.011609   \n",
       "201655131        0.095768               0.035803       0.015786   \n",
       "201655133        0.112053               0.038018       0.014992   \n",
       "201655139        0.116369               0.030078       0.022100   \n",
       "201655141        0.087108               0.067083       0.013280   \n",
       "201656021        0.116443               0.061820       0.033988   \n",
       "201656025        0.103022               0.057952       0.025090   \n",
       "\n",
       "           finance_insurance_realestate_1  prof_scientific_waste_1  \\\n",
       "new_index                                                            \n",
       "201101003                        0.059526                 0.086022   \n",
       "201101015                        0.020522                 0.097882   \n",
       "201101043                        0.060985                 0.096501   \n",
       "201101049                        0.026380                 0.080747   \n",
       "201101051                        0.060985                 0.096501   \n",
       "201101055                        0.038159                 0.045908   \n",
       "201101069                        0.038269                 0.091149   \n",
       "201101073                        0.087961                 0.116549   \n",
       "201101077                        0.060985                 0.096501   \n",
       "201101081                        0.040722                 0.076828   \n",
       "201101083                        0.060985                 0.096501   \n",
       "201101089                        0.040669                 0.175376   \n",
       "201101095                        0.036929                 0.062762   \n",
       "201101097                        0.056813                 0.097774   \n",
       "201101101                        0.053563                 0.102832   \n",
       "201101103                        0.044374                 0.081258   \n",
       "201101115                        0.060985                 0.096501   \n",
       "201101117                        0.112044                 0.137249   \n",
       "201101121                        0.060985                 0.096501   \n",
       "201101125                        0.054224                 0.067698   \n",
       "201101127                        0.060985                 0.096501   \n",
       "201102020                        0.049245                 0.110399   \n",
       "201102090                        0.036130                 0.077480   \n",
       "201102170                        0.042721                 0.086338   \n",
       "201104001                        0.060985                 0.096501   \n",
       "201104003                        0.060985                 0.096501   \n",
       "201104005                        0.051573                 0.065732   \n",
       "201104013                        0.099774                 0.130022   \n",
       "201104015                        0.052163                 0.076398   \n",
       "201104017                        0.060985                 0.096501   \n",
       "...                                   ...                      ...   \n",
       "201654033                        0.037357                 0.065794   \n",
       "201654039                        0.065889                 0.100224   \n",
       "201654061                        0.046173                 0.109550   \n",
       "201654081                        0.060702                 0.100859   \n",
       "201654107                        0.040665                 0.051311   \n",
       "201655009                        0.073024                 0.084382   \n",
       "201655025                        0.082944                 0.137849   \n",
       "201655027                        0.044261                 0.058373   \n",
       "201655035                        0.059241                 0.069514   \n",
       "201655039                        0.046906                 0.049081   \n",
       "201655055                        0.055012                 0.072291   \n",
       "201655059                        0.040375                 0.085926   \n",
       "201655063                        0.053741                 0.071180   \n",
       "201655071                        0.044403                 0.038843   \n",
       "201655073                        0.090070                 0.067402   \n",
       "201655079                        0.061934                 0.106110   \n",
       "201655087                        0.066174                 0.090829   \n",
       "201655089                        0.064551                 0.108895   \n",
       "201655097                        0.121597                 0.056865   \n",
       "201655101                        0.053119                 0.086634   \n",
       "201655105                        0.041678                 0.066037   \n",
       "201655109                        0.069111                 0.108966   \n",
       "201655117                        0.067037                 0.053613   \n",
       "201655127                        0.037276                 0.083076   \n",
       "201655131                        0.062445                 0.080276   \n",
       "201655133                        0.082146                 0.110605   \n",
       "201655139                        0.059290                 0.080581   \n",
       "201655141                        0.068585                 0.055542   \n",
       "201656021                        0.038453                 0.071162   \n",
       "201656025                        0.062317                 0.074406   \n",
       "\n",
       "           edu_health_1  arts_recreation_1   other_1  public_admin_1  \n",
       "new_index                                                             \n",
       "201101003      0.221214           0.113281  0.048301        0.036560  \n",
       "201101015      0.204400           0.081013  0.051918        0.098368  \n",
       "201101043      0.240508           0.093014  0.048994        0.053334  \n",
       "201101049      0.203203           0.053307  0.068601        0.042632  \n",
       "201101051      0.240508           0.093014  0.048994        0.053334  \n",
       "201101055      0.250481           0.113808  0.051323        0.062973  \n",
       "201101069      0.225213           0.090322  0.061995        0.051472  \n",
       "201101073      0.272641           0.075168  0.058147        0.044486  \n",
       "201101077      0.240508           0.093014  0.048994        0.053334  \n",
       "201101081      0.288127           0.103079  0.061226        0.039910  \n",
       "201101083      0.240508           0.093014  0.048994        0.053334  \n",
       "201101089      0.179244           0.081932  0.051930        0.087763  \n",
       "201101095      0.198167           0.063507  0.053378        0.043829  \n",
       "201101097      0.233898           0.087059  0.059638        0.039582  \n",
       "201101101      0.216640           0.102690  0.057959        0.119482  \n",
       "201101103      0.193365           0.075295  0.059207        0.033121  \n",
       "201101115      0.240508           0.093014  0.048994        0.053334  \n",
       "201101117      0.197602           0.061784  0.059296        0.046985  \n",
       "201101121      0.240508           0.093014  0.048994        0.053334  \n",
       "201101125      0.284911           0.119719  0.042211        0.048357  \n",
       "201101127      0.240508           0.093014  0.048994        0.053334  \n",
       "201102020      0.249707           0.100512  0.042225        0.111625  \n",
       "201102090      0.217588           0.078668  0.049263        0.150334  \n",
       "201102170      0.251476           0.078537  0.039822        0.083070  \n",
       "201104001      0.240508           0.093014  0.048994        0.053334  \n",
       "201104003      0.240508           0.093014  0.048994        0.053334  \n",
       "201104005      0.247508           0.201433  0.033754        0.071978  \n",
       "201104013      0.203000           0.097778  0.048240        0.046061  \n",
       "201104015      0.189562           0.174207  0.034375        0.076340  \n",
       "201104017      0.240508           0.093014  0.048994        0.053334  \n",
       "...                 ...                ...       ...             ...  \n",
       "201654033      0.296526           0.085022  0.047601        0.115786  \n",
       "201654039      0.270667           0.100113  0.040842        0.112526  \n",
       "201654061      0.360388           0.121354  0.035513        0.059201  \n",
       "201654081      0.238304           0.097315  0.048328        0.049026  \n",
       "201654107      0.320483           0.099258  0.045223        0.089474  \n",
       "201655009      0.202846           0.093170  0.039007        0.020846  \n",
       "201655025      0.285833           0.090658  0.039668        0.044714  \n",
       "201655027      0.185140           0.063427  0.048549        0.030040  \n",
       "201655035      0.267207           0.079175  0.047544        0.033937  \n",
       "201655039      0.209634           0.063600  0.035435        0.045790  \n",
       "201655055      0.238870           0.077360  0.043771        0.026514  \n",
       "201655059      0.225782           0.084677  0.045349        0.048229  \n",
       "201655063      0.298961           0.108936  0.046355        0.032293  \n",
       "201655071      0.210480           0.062227  0.037088        0.020994  \n",
       "201655073      0.227370           0.071343  0.035559        0.027045  \n",
       "201655079      0.258274           0.097210  0.044666        0.035156  \n",
       "201655087      0.207668           0.079542  0.031116        0.027592  \n",
       "201655089      0.233125           0.077941  0.032854        0.033925  \n",
       "201655097      0.258078           0.072386  0.036948        0.027890  \n",
       "201655101      0.207000           0.076496  0.040780        0.032095  \n",
       "201655105      0.212013           0.071704  0.030623        0.029149  \n",
       "201655109      0.196570           0.070616  0.057046        0.037007  \n",
       "201655117      0.185135           0.076792  0.039122        0.025314  \n",
       "201655127      0.225702           0.106738  0.033728        0.025108  \n",
       "201655131      0.207379           0.075402  0.050286        0.037876  \n",
       "201655133      0.223792           0.076854  0.036258        0.027043  \n",
       "201655139      0.199925           0.090166  0.043299        0.024915  \n",
       "201655141      0.256396           0.064132  0.034595        0.043448  \n",
       "201656021      0.259028           0.067737  0.059652        0.127411  \n",
       "201656025      0.262701           0.086711  0.050420        0.036316  \n",
       "\n",
       "[4884 rows x 88 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_X.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv(\"score_Uran.csv\")\n",
    "score.columns = ['fips', '2000', '2001', '2002', '2003', '2004', '2005', '2006',\n",
    "       '2007', '2008', '2009', '2010', '2011', '2012', '2015', '2016', '2013',\n",
    "       '2014', '1999']\n",
    "#score = score.set_index('fips')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score.drop(['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','1999'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = pd.wide_to_long(score, ['20'], i = 'fips', j = 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score2 = score2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2.columns = ['fips', 'year', 'score']\n",
    "score2.year = score2.year.apply(str)\n",
    "score2.fips = score2.fips.apply(str)\n",
    "score2['new_index'] = '20' + score2.year + score2.fips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = score2.set_index(['new_index'])\n",
    "score2 = score2.drop(['fips', 'year'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Y = pd.concat([final_X, score2], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2546"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Y = X_Y.drop(['Unnamed: 0', 'index', 'fips'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_agri_fish_mine</th>\n",
       "      <th>agri_fish_hunt</th>\n",
       "      <th>mining_quarrying_oilgas_extract</th>\n",
       "      <th>construction</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>wholesale_trade</th>\n",
       "      <th>retail_trade</th>\n",
       "      <th>transport_warehouse_utilities</th>\n",
       "      <th>transport_warehouse</th>\n",
       "      <th>utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>retail_trade_1</th>\n",
       "      <th>transport_utilities_1</th>\n",
       "      <th>information_1</th>\n",
       "      <th>finance_insurance_realestate_1</th>\n",
       "      <th>prof_scientific_waste_1</th>\n",
       "      <th>edu_health_1</th>\n",
       "      <th>arts_recreation_1</th>\n",
       "      <th>other_1</th>\n",
       "      <th>public_admin_1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201112001</th>\n",
       "      <td>0.028110</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.064727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.019768</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.041948</td>\n",
       "      <td>0.092094</td>\n",
       "      <td>0.404855</td>\n",
       "      <td>0.130712</td>\n",
       "      <td>0.036648</td>\n",
       "      <td>0.050313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112005</th>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.034199</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.043527</td>\n",
       "      <td>0.034563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117235</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>0.083460</td>\n",
       "      <td>0.123060</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>0.037080</td>\n",
       "      <td>0.069798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112009</th>\n",
       "      <td>0.033982</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>0.037284</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>0.041110</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>0.051450</td>\n",
       "      <td>0.051392</td>\n",
       "      <td>0.051590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148813</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.130818</td>\n",
       "      <td>0.219768</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.051668</td>\n",
       "      <td>0.076642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112011</th>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>0.042748</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.040273</td>\n",
       "      <td>0.044480</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>0.045035</td>\n",
       "      <td>0.044115</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135109</td>\n",
       "      <td>0.044505</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.080922</td>\n",
       "      <td>0.137408</td>\n",
       "      <td>0.220093</td>\n",
       "      <td>0.109108</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.043507</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112015</th>\n",
       "      <td>0.048166</td>\n",
       "      <td>0.048166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047824</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.056826</td>\n",
       "      <td>0.027990</td>\n",
       "      <td>0.054805</td>\n",
       "      <td>0.052671</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112017</th>\n",
       "      <td>0.033194</td>\n",
       "      <td>0.021236</td>\n",
       "      <td>0.041331</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.045640</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>0.065955</td>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112019</th>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.097020</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>0.023518</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>0.053057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152683</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.216756</td>\n",
       "      <td>0.103497</td>\n",
       "      <td>0.049308</td>\n",
       "      <td>0.065317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112021</th>\n",
       "      <td>0.017199</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>0.043969</td>\n",
       "      <td>0.030951</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.038677</td>\n",
       "      <td>0.053560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115043</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.126875</td>\n",
       "      <td>0.182843</td>\n",
       "      <td>0.141784</td>\n",
       "      <td>0.080933</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112023</th>\n",
       "      <td>0.065485</td>\n",
       "      <td>0.033807</td>\n",
       "      <td>0.072302</td>\n",
       "      <td>0.036961</td>\n",
       "      <td>0.050401</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.023024</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112031</th>\n",
       "      <td>0.035460</td>\n",
       "      <td>0.032838</td>\n",
       "      <td>0.061369</td>\n",
       "      <td>0.035095</td>\n",
       "      <td>0.042533</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.047248</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>0.062941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122249</td>\n",
       "      <td>0.069966</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.115629</td>\n",
       "      <td>0.118658</td>\n",
       "      <td>0.195105</td>\n",
       "      <td>0.115136</td>\n",
       "      <td>0.045048</td>\n",
       "      <td>0.056154</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112033</th>\n",
       "      <td>0.034259</td>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.049319</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.047793</td>\n",
       "      <td>0.048116</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>0.050423</td>\n",
       "      <td>0.048738</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139416</td>\n",
       "      <td>0.048515</td>\n",
       "      <td>0.024953</td>\n",
       "      <td>0.063205</td>\n",
       "      <td>0.115216</td>\n",
       "      <td>0.241946</td>\n",
       "      <td>0.114828</td>\n",
       "      <td>0.053456</td>\n",
       "      <td>0.061675</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112035</th>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.028814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054952</td>\n",
       "      <td>0.054701</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.029576</td>\n",
       "      <td>0.049798</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112053</th>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.036554</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>0.051460</td>\n",
       "      <td>0.028805</td>\n",
       "      <td>0.051263</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.058324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>0.050589</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>0.072137</td>\n",
       "      <td>0.219346</td>\n",
       "      <td>0.066540</td>\n",
       "      <td>0.059686</td>\n",
       "      <td>0.066431</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112055</th>\n",
       "      <td>0.024782</td>\n",
       "      <td>0.024782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041418</td>\n",
       "      <td>0.049194</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.051464</td>\n",
       "      <td>0.050476</td>\n",
       "      <td>0.101374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112057</th>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.034953</td>\n",
       "      <td>0.041646</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>0.023839</td>\n",
       "      <td>0.044307</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118959</td>\n",
       "      <td>0.043724</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.109034</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.207753</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.039637</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112061</th>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.054376</td>\n",
       "      <td>0.035337</td>\n",
       "      <td>0.042703</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.043432</td>\n",
       "      <td>0.038909</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128671</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.070198</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>0.215667</td>\n",
       "      <td>0.122365</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112069</th>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.023716</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>0.032834</td>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.044475</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.035912</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150491</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.113005</td>\n",
       "      <td>0.192990</td>\n",
       "      <td>0.182436</td>\n",
       "      <td>0.049240</td>\n",
       "      <td>0.051608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112071</th>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>0.050803</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.042855</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137938</td>\n",
       "      <td>0.048408</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.121182</td>\n",
       "      <td>0.211394</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.044726</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112073</th>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.150535</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.049843</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>0.047614</td>\n",
       "      <td>0.036892</td>\n",
       "      <td>0.055898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116520</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>0.133168</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.108641</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.126958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112081</th>\n",
       "      <td>0.027530</td>\n",
       "      <td>0.027330</td>\n",
       "      <td>0.045879</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.045557</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>0.026349</td>\n",
       "      <td>0.044817</td>\n",
       "      <td>0.039865</td>\n",
       "      <td>0.052014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161784</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.121624</td>\n",
       "      <td>0.212962</td>\n",
       "      <td>0.086070</td>\n",
       "      <td>0.061855</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112083</th>\n",
       "      <td>0.029966</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.041011</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.049246</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.052596</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>0.067855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151906</td>\n",
       "      <td>0.056246</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.119440</td>\n",
       "      <td>0.222281</td>\n",
       "      <td>0.122796</td>\n",
       "      <td>0.036892</td>\n",
       "      <td>0.037813</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112085</th>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.013275</td>\n",
       "      <td>0.047536</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.052244</td>\n",
       "      <td>0.033617</td>\n",
       "      <td>0.077884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.050814</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.219986</td>\n",
       "      <td>0.118947</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112086</th>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.055512</td>\n",
       "      <td>0.031359</td>\n",
       "      <td>0.032122</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.042792</td>\n",
       "      <td>0.040637</td>\n",
       "      <td>0.057022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138089</td>\n",
       "      <td>0.073670</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.065411</td>\n",
       "      <td>0.127202</td>\n",
       "      <td>0.204518</td>\n",
       "      <td>0.110786</td>\n",
       "      <td>0.059482</td>\n",
       "      <td>0.037436</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112087</th>\n",
       "      <td>0.024522</td>\n",
       "      <td>0.023407</td>\n",
       "      <td>0.089461</td>\n",
       "      <td>0.034480</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.024294</td>\n",
       "      <td>0.033675</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>0.059849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112089</th>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036030</td>\n",
       "      <td>0.058903</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>0.046555</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.045767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.240508</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112091</th>\n",
       "      <td>0.027961</td>\n",
       "      <td>0.027362</td>\n",
       "      <td>0.037997</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.045430</td>\n",
       "      <td>0.041478</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>0.048970</td>\n",
       "      <td>0.048737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.134240</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.124459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112095</th>\n",
       "      <td>0.020273</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.077168</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.023648</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.047292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122424</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>0.025545</td>\n",
       "      <td>0.064456</td>\n",
       "      <td>0.143201</td>\n",
       "      <td>0.188444</td>\n",
       "      <td>0.189584</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112097</th>\n",
       "      <td>0.023919</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.119829</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.160155</td>\n",
       "      <td>0.273923</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112099</th>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.045308</td>\n",
       "      <td>0.032357</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.044028</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.045873</td>\n",
       "      <td>0.041312</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135781</td>\n",
       "      <td>0.047036</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.078415</td>\n",
       "      <td>0.134880</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>0.062776</td>\n",
       "      <td>0.042159</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201112101</th>\n",
       "      <td>0.027861</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.053464</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.046384</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155981</td>\n",
       "      <td>0.055595</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.123644</td>\n",
       "      <td>0.231692</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>0.048633</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654003</th>\n",
       "      <td>0.031013</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>0.047010</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.048993</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>0.069720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111641</td>\n",
       "      <td>0.048391</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.055690</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>0.225832</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>0.039622</td>\n",
       "      <td>0.084122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654011</th>\n",
       "      <td>0.066465</td>\n",
       "      <td>0.053993</td>\n",
       "      <td>0.069810</td>\n",
       "      <td>0.034341</td>\n",
       "      <td>0.054160</td>\n",
       "      <td>0.039151</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.047517</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.054776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.238304</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.049026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654033</th>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>0.053144</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.040709</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.061230</td>\n",
       "      <td>0.057902</td>\n",
       "      <td>0.074372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118177</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.296526</td>\n",
       "      <td>0.085022</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>0.115786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654039</th>\n",
       "      <td>0.065192</td>\n",
       "      <td>0.021054</td>\n",
       "      <td>0.066869</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.046981</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.062817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079815</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.065889</td>\n",
       "      <td>0.100224</td>\n",
       "      <td>0.270667</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.112526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654061</th>\n",
       "      <td>0.070675</td>\n",
       "      <td>0.034348</td>\n",
       "      <td>0.072753</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>0.061884</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.048435</td>\n",
       "      <td>0.038178</td>\n",
       "      <td>0.060376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.121354</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.059201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654081</th>\n",
       "      <td>0.083178</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>0.085379</td>\n",
       "      <td>0.038580</td>\n",
       "      <td>0.046436</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>0.042263</td>\n",
       "      <td>0.073081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.100859</td>\n",
       "      <td>0.238304</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.049026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201654107</th>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.049369</td>\n",
       "      <td>0.059183</td>\n",
       "      <td>0.036634</td>\n",
       "      <td>0.059202</td>\n",
       "      <td>0.052677</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>0.052558</td>\n",
       "      <td>0.076137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131056</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.320483</td>\n",
       "      <td>0.099258</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655009</th>\n",
       "      <td>0.027547</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.063987</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.043561</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.048399</td>\n",
       "      <td>0.041454</td>\n",
       "      <td>0.080710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105683</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>0.084382</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>0.093170</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655025</th>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.028114</td>\n",
       "      <td>0.036904</td>\n",
       "      <td>0.045140</td>\n",
       "      <td>0.044259</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>0.068870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100363</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.082944</td>\n",
       "      <td>0.137849</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>0.090658</td>\n",
       "      <td>0.039668</td>\n",
       "      <td>0.044714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655027</th>\n",
       "      <td>0.026795</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.050854</td>\n",
       "      <td>0.046819</td>\n",
       "      <td>0.073276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.047324</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.185140</td>\n",
       "      <td>0.063427</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655035</th>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.126234</td>\n",
       "      <td>0.037685</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>0.054817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193205</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.059241</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.267207</td>\n",
       "      <td>0.079175</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655039</th>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.050728</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.057332</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.078453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.049081</td>\n",
       "      <td>0.209634</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.045790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655055</th>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.045018</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.067010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.238870</td>\n",
       "      <td>0.077360</td>\n",
       "      <td>0.043771</td>\n",
       "      <td>0.026514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655059</th>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.038701</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169675</td>\n",
       "      <td>0.056785</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.085926</td>\n",
       "      <td>0.225782</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>0.048229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655063</th>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.044189</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.050402</td>\n",
       "      <td>0.073579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127378</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.032632</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>0.298961</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.032293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655071</th>\n",
       "      <td>0.034781</td>\n",
       "      <td>0.033315</td>\n",
       "      <td>0.054173</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>0.047011</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>0.085358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092097</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.020994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655073</th>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.027021</td>\n",
       "      <td>0.038863</td>\n",
       "      <td>0.046943</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>0.023274</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.089742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109750</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.090070</td>\n",
       "      <td>0.067402</td>\n",
       "      <td>0.227370</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655079</th>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.027144</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>0.039166</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>0.044644</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.042563</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.067335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110877</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.061934</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.258274</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655087</th>\n",
       "      <td>0.027341</td>\n",
       "      <td>0.027674</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.046574</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>0.047182</td>\n",
       "      <td>0.044520</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>0.090829</td>\n",
       "      <td>0.207668</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.027592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655089</th>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.041052</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.037130</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.071077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109572</td>\n",
       "      <td>0.037420</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.108895</td>\n",
       "      <td>0.233125</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.033925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655097</th>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.030192</td>\n",
       "      <td>0.064455</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>0.047595</td>\n",
       "      <td>0.044847</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.052509</td>\n",
       "      <td>0.051464</td>\n",
       "      <td>0.098640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125702</td>\n",
       "      <td>0.051065</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.027890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655101</th>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.048088</td>\n",
       "      <td>0.047008</td>\n",
       "      <td>0.023239</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>0.035657</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>0.086634</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.076496</td>\n",
       "      <td>0.040780</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655105</th>\n",
       "      <td>0.032364</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.108631</td>\n",
       "      <td>0.044023</td>\n",
       "      <td>0.042340</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>0.068468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115378</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.066037</td>\n",
       "      <td>0.212013</td>\n",
       "      <td>0.071704</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655109</th>\n",
       "      <td>0.019602</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.036892</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>0.046837</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.075012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>0.023498</td>\n",
       "      <td>0.069111</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>0.070616</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.037007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655117</th>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.037738</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.049222</td>\n",
       "      <td>0.052010</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.028649</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.067037</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.185135</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.025314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655127</th>\n",
       "      <td>0.029304</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>0.028732</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.046045</td>\n",
       "      <td>0.052204</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.060050</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.091085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134970</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>0.225702</td>\n",
       "      <td>0.106738</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.025108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655131</th>\n",
       "      <td>0.033418</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.052911</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.046476</td>\n",
       "      <td>0.047754</td>\n",
       "      <td>0.024611</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>0.039373</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095768</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.015786</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>0.207379</td>\n",
       "      <td>0.075402</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655133</th>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.070681</td>\n",
       "      <td>0.043071</td>\n",
       "      <td>0.049311</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>0.045799</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.066659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.082146</td>\n",
       "      <td>0.110605</td>\n",
       "      <td>0.223792</td>\n",
       "      <td>0.076854</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.027043</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655139</th>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>0.049006</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.043036</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.041699</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.080581</td>\n",
       "      <td>0.199925</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201655141</th>\n",
       "      <td>0.039303</td>\n",
       "      <td>0.039496</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.048049</td>\n",
       "      <td>0.047298</td>\n",
       "      <td>0.072554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.067083</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.068585</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>0.043448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2546 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           total_agri_fish_mine  agri_fish_hunt  \\\n",
       "new_index                                         \n",
       "201112001              0.028110        0.026952   \n",
       "201112005              0.032231        0.031088   \n",
       "201112009              0.033982        0.030093   \n",
       "201112011              0.026832        0.023080   \n",
       "201112015              0.048166        0.048166   \n",
       "201112017              0.033194        0.021236   \n",
       "201112019              0.018299        0.017358   \n",
       "201112021              0.017199        0.017139   \n",
       "201112023              0.065485        0.033807   \n",
       "201112031              0.035460        0.032838   \n",
       "201112033              0.034259        0.031024   \n",
       "201112035              0.033494        0.028814   \n",
       "201112053              0.042109        0.036554   \n",
       "201112055              0.024782        0.024782   \n",
       "201112057              0.019112        0.018031   \n",
       "201112061              0.018702        0.017754   \n",
       "201112069              0.024383        0.023716   \n",
       "201112071              0.028309        0.025063   \n",
       "201112073              0.031008        0.029842   \n",
       "201112081              0.027530        0.027330   \n",
       "201112083              0.029966        0.029187   \n",
       "201112085              0.013703        0.013275   \n",
       "201112086              0.021150        0.020333   \n",
       "201112087              0.024522        0.023407   \n",
       "201112089              0.044359        0.042676   \n",
       "201112091              0.027961        0.027362   \n",
       "201112095              0.020273        0.020158   \n",
       "201112097              0.023919        0.022169   \n",
       "201112099              0.017949        0.017772   \n",
       "201112101              0.027861        0.027419   \n",
       "...                         ...             ...   \n",
       "201654003              0.031013        0.021000   \n",
       "201654011              0.066465        0.053993   \n",
       "201654033              0.052059        0.020776   \n",
       "201654039              0.065192        0.021054   \n",
       "201654061              0.070675        0.034348   \n",
       "201654081              0.083178        0.018873   \n",
       "201654107              0.058710        0.049369   \n",
       "201655009              0.027547        0.026961   \n",
       "201655025              0.028217        0.028114   \n",
       "201655027              0.026795        0.025934   \n",
       "201655035              0.025389        0.023458   \n",
       "201655039              0.032852        0.031033   \n",
       "201655055              0.029166        0.028851   \n",
       "201655059              0.026700        0.025640   \n",
       "201655063              0.024941        0.023626   \n",
       "201655071              0.034781        0.033315   \n",
       "201655073              0.027478        0.027021   \n",
       "201655079              0.028600        0.027144   \n",
       "201655087              0.027341        0.027674   \n",
       "201655089              0.016809        0.016503   \n",
       "201655097              0.031166        0.030192   \n",
       "201655101              0.026240        0.024256   \n",
       "201655105              0.032364        0.030649   \n",
       "201655109              0.019602        0.018930   \n",
       "201655117              0.032387        0.032009   \n",
       "201655127              0.029304        0.029493   \n",
       "201655131              0.033418        0.031374   \n",
       "201655133              0.025591        0.022200   \n",
       "201655139              0.030307        0.029802   \n",
       "201655141              0.039303        0.039496   \n",
       "\n",
       "           mining_quarrying_oilgas_extract  construction  manufacturing  \\\n",
       "new_index                                                                 \n",
       "201112001                         0.054643      0.036884       0.046544   \n",
       "201112005                         0.049285      0.034199       0.044176   \n",
       "201112009                         0.040310      0.037284       0.051911   \n",
       "201112011                         0.042748      0.033875       0.040273   \n",
       "201112015                         0.000000      0.047824       0.046507   \n",
       "201112017                         0.041331      0.039223       0.045640   \n",
       "201112019                         0.097020      0.040799       0.047414   \n",
       "201112021                         0.043005      0.034412       0.043969   \n",
       "201112023                         0.072302      0.036961       0.050401   \n",
       "201112031                         0.061369      0.035095       0.042533   \n",
       "201112033                         0.049319      0.034728       0.047793   \n",
       "201112035                         0.000000      0.054952       0.054701   \n",
       "201112053                         0.055401      0.038453       0.046976   \n",
       "201112055                         0.000000      0.041418       0.049194   \n",
       "201112057                         0.046753      0.034953       0.041646   \n",
       "201112061                         0.054376      0.035337       0.042703   \n",
       "201112069                         0.042021      0.032834       0.034532   \n",
       "201112071                         0.032869      0.041040       0.045425   \n",
       "201112073                         0.150535      0.035399       0.049843   \n",
       "201112081                         0.045879      0.038898       0.045557   \n",
       "201112083                         0.046393      0.041011       0.045032   \n",
       "201112085                         0.047536      0.026450       0.037640   \n",
       "201112086                         0.055512      0.031359       0.032122   \n",
       "201112087                         0.089461      0.034480       0.038246   \n",
       "201112089                         0.000000      0.036030       0.058903   \n",
       "201112091                         0.037997      0.038422       0.045430   \n",
       "201112095                         0.077168      0.033121       0.043701   \n",
       "201112097                         0.119829      0.033501       0.038038   \n",
       "201112099                         0.045308      0.032357       0.045784   \n",
       "201112101                         0.053464      0.035662       0.041640   \n",
       "...                                    ...           ...            ...   \n",
       "201654003                         0.053571      0.046334       0.046747   \n",
       "201654011                         0.069810      0.034341       0.054160   \n",
       "201654033                         0.053144      0.035620       0.060067   \n",
       "201654039                         0.066869      0.036992       0.048076   \n",
       "201654061                         0.072753      0.046747       0.061884   \n",
       "201654081                         0.085379      0.038580       0.046436   \n",
       "201654107                         0.059183      0.036634       0.059202   \n",
       "201655009                         0.063987      0.042343       0.043561   \n",
       "201655025                         0.036904      0.045140       0.044259   \n",
       "201655027                         0.040963      0.049775       0.045017   \n",
       "201655035                         0.126234      0.037685       0.043461   \n",
       "201655039                         0.039375      0.055944       0.050728   \n",
       "201655055                         0.045018      0.047836       0.044370   \n",
       "201655059                         0.031239      0.048009       0.048374   \n",
       "201655063                         0.077635      0.044189       0.042173   \n",
       "201655071                         0.054173      0.044268       0.047011   \n",
       "201655073                         0.038863      0.046943       0.044593   \n",
       "201655079                         0.040799      0.039166       0.044735   \n",
       "201655087                         0.015093      0.046574       0.052433   \n",
       "201655089                         0.055398      0.041052       0.046083   \n",
       "201655097                         0.064455      0.050368       0.047595   \n",
       "201655101                         0.061202      0.043799       0.048088   \n",
       "201655105                         0.108631      0.044023       0.042340   \n",
       "201655109                         0.128932      0.036892       0.042873   \n",
       "201655117                         0.037738      0.048351       0.049222   \n",
       "201655127                         0.028732      0.048606       0.046045   \n",
       "201655131                         0.052911      0.043691       0.046476   \n",
       "201655133                         0.070681      0.043071       0.049311   \n",
       "201655139                         0.049006      0.042554       0.045391   \n",
       "201655141                         0.017998      0.053359       0.054011   \n",
       "\n",
       "           wholesale_trade  retail_trade  transport_warehouse_utilities  \\\n",
       "new_index                                                                 \n",
       "201112001         0.050729      0.022339                       0.043884   \n",
       "201112005         0.035694      0.021647                       0.041688   \n",
       "201112009         0.041110      0.022408                       0.051450   \n",
       "201112011         0.044480      0.026107                       0.045035   \n",
       "201112015         0.056826      0.027990                       0.054805   \n",
       "201112017         0.037490      0.023596                       0.065955   \n",
       "201112019         0.055008      0.023518                       0.048192   \n",
       "201112021         0.030951      0.024749                       0.040032   \n",
       "201112023         0.026240      0.023024                       0.050205   \n",
       "201112031         0.045784      0.024229                       0.047248   \n",
       "201112033         0.048116      0.024105                       0.050423   \n",
       "201112035         0.048584      0.029576                       0.049798   \n",
       "201112053         0.051460      0.028805                       0.051263   \n",
       "201112055         0.043011      0.030029                       0.051464   \n",
       "201112057         0.042745      0.023839                       0.044307   \n",
       "201112061         0.047235      0.025644                       0.043432   \n",
       "201112069         0.044475      0.020734                       0.038800   \n",
       "201112071         0.050803      0.027725                       0.042855   \n",
       "201112073         0.040649      0.019869                       0.047614   \n",
       "201112081         0.045202      0.026349                       0.044817   \n",
       "201112083         0.049246      0.029059                       0.052596   \n",
       "201112085         0.036692      0.017906                       0.052244   \n",
       "201112086         0.039492      0.025618                       0.042792   \n",
       "201112087         0.052966      0.024294                       0.033675   \n",
       "201112089         0.050624      0.023074                       0.046555   \n",
       "201112091         0.041478      0.025531                       0.048942   \n",
       "201112095         0.042060      0.023648                       0.039409   \n",
       "201112097         0.033876      0.022734                       0.034570   \n",
       "201112099         0.044028      0.025008                       0.045873   \n",
       "201112101         0.046384      0.023485                       0.044907   \n",
       "...                    ...           ...                            ...   \n",
       "201654003         0.047010      0.024016                       0.048993   \n",
       "201654011         0.039151      0.016672                       0.047517   \n",
       "201654033         0.040709      0.021352                       0.061230   \n",
       "201654039         0.050153      0.019401                       0.046981   \n",
       "201654061         0.042841      0.018106                       0.048435   \n",
       "201654081         0.048689      0.025055                       0.048148   \n",
       "201654107         0.052677      0.020274                       0.057737   \n",
       "201655009         0.047191      0.019604                       0.048399   \n",
       "201655025         0.047057      0.023567                       0.043796   \n",
       "201655027         0.040873      0.023659                       0.050854   \n",
       "201655035         0.045257      0.025309                       0.042217   \n",
       "201655039         0.050300      0.028361                       0.057332   \n",
       "201655055         0.046476      0.023603                       0.053563   \n",
       "201655059         0.043799      0.022430                       0.047041   \n",
       "201655063         0.049511      0.024962                       0.056024   \n",
       "201655071         0.042103      0.020053                       0.059340   \n",
       "201655073         0.044361      0.023274                       0.044419   \n",
       "201655079         0.044644      0.022630                       0.042563   \n",
       "201655087         0.048134      0.020997                       0.047182   \n",
       "201655089         0.056247      0.016178                       0.037130   \n",
       "201655097         0.044847      0.021116                       0.052509   \n",
       "201655101         0.047008      0.023239                       0.043107   \n",
       "201655105         0.038137      0.023337                       0.048681   \n",
       "201655109         0.046837      0.021492                       0.043988   \n",
       "201655117         0.052010      0.024143                       0.052240   \n",
       "201655127         0.052204      0.023123                       0.060050   \n",
       "201655131         0.047754      0.024611                       0.045051   \n",
       "201655133         0.047971      0.024183                       0.045799   \n",
       "201655139         0.043036      0.019420                       0.041699   \n",
       "201655141         0.041534      0.024823                       0.048049   \n",
       "\n",
       "           transport_warehouse  utilities  ...    retail_trade_1  \\\n",
       "new_index                                  ...                     \n",
       "201112001             0.039177   0.064727  ...          0.099125   \n",
       "201112005             0.043527   0.034563  ...          0.117235   \n",
       "201112009             0.051392   0.051590  ...          0.148813   \n",
       "201112011             0.044115   0.058173  ...          0.135109   \n",
       "201112015             0.052671   0.056581  ...          0.119457   \n",
       "201112017             0.047088   0.098332  ...          0.119457   \n",
       "201112019             0.047511   0.053057  ...          0.152683   \n",
       "201112021             0.038677   0.053560  ...          0.115043   \n",
       "201112023             0.050250   0.049932  ...          0.119457   \n",
       "201112031             0.046036   0.062941  ...          0.122249   \n",
       "201112033             0.048738   0.053119  ...          0.139416   \n",
       "201112035             0.050157   0.047847  ...          0.119457   \n",
       "201112053             0.049853   0.058324  ...          0.158840   \n",
       "201112055             0.050476   0.101374  ...          0.119457   \n",
       "201112057             0.042213   0.066578  ...          0.118959   \n",
       "201112061             0.038909   0.063886  ...          0.128671   \n",
       "201112069             0.035912   0.047363  ...          0.150491   \n",
       "201112071             0.041945   0.045219  ...          0.137938   \n",
       "201112073             0.036892   0.055898  ...          0.116520   \n",
       "201112081             0.039865   0.052014  ...          0.161784   \n",
       "201112083             0.049938   0.067855  ...          0.151906   \n",
       "201112085             0.033617   0.077884  ...          0.153333   \n",
       "201112086             0.040637   0.057022  ...          0.138089   \n",
       "201112087             0.029698   0.059849  ...          0.119457   \n",
       "201112089             0.046874   0.045767  ...          0.119457   \n",
       "201112091             0.048970   0.048737  ...          0.097791   \n",
       "201112095             0.038022   0.047292  ...          0.122424   \n",
       "201112097             0.034190   0.037176  ...          0.144831   \n",
       "201112099             0.041312   0.062061  ...          0.135781   \n",
       "201112101             0.041447   0.055534  ...          0.155981   \n",
       "...                        ...        ...  ...               ...   \n",
       "201654003             0.046605   0.069720  ...          0.111641   \n",
       "201654011             0.047448   0.054776  ...          0.119262   \n",
       "201654033             0.057902   0.074372  ...          0.118177   \n",
       "201654039             0.044705   0.062817  ...          0.079815   \n",
       "201654061             0.038178   0.060376  ...          0.073314   \n",
       "201654081             0.042263   0.073081  ...          0.119262   \n",
       "201654107             0.052558   0.076137  ...          0.131056   \n",
       "201655009             0.041454   0.080710  ...          0.105683   \n",
       "201655025             0.034852   0.068870  ...          0.100363   \n",
       "201655027             0.046819   0.073276  ...          0.105413   \n",
       "201655035             0.038335   0.054817  ...          0.193205   \n",
       "201655039             0.052742   0.078453  ...          0.103813   \n",
       "201655055             0.050736   0.067010  ...          0.118884   \n",
       "201655059             0.038701   0.094353  ...          0.169675   \n",
       "201655063             0.050402   0.073579  ...          0.127378   \n",
       "201655071             0.046177   0.085358  ...          0.092097   \n",
       "201655073             0.041263   0.089742  ...          0.109750   \n",
       "201655079             0.038967   0.067335  ...          0.110877   \n",
       "201655087             0.044520   0.064540  ...          0.127579   \n",
       "201655089             0.031481   0.071077  ...          0.109572   \n",
       "201655097             0.051464   0.098640  ...          0.125702   \n",
       "201655101             0.035657   0.078342  ...          0.125592   \n",
       "201655105             0.045340   0.068468  ...          0.115378   \n",
       "201655109             0.042634   0.075012  ...          0.096718   \n",
       "201655117             0.047749   0.078161  ...          0.113262   \n",
       "201655127             0.053500   0.091085  ...          0.134970   \n",
       "201655131             0.039373   0.065477  ...          0.095768   \n",
       "201655133             0.038763   0.066659  ...          0.112053   \n",
       "201655139             0.038361   0.060221  ...          0.116369   \n",
       "201655141             0.047298   0.072554  ...          0.087108   \n",
       "\n",
       "           transport_utilities_1  information_1  \\\n",
       "new_index                                         \n",
       "201112001               0.019768       0.016429   \n",
       "201112005               0.057312       0.028316   \n",
       "201112009               0.035189       0.012500   \n",
       "201112011               0.044505       0.024667   \n",
       "201112015               0.048909       0.019094   \n",
       "201112017               0.048909       0.019094   \n",
       "201112019               0.054555       0.021781   \n",
       "201112021               0.024181       0.008213   \n",
       "201112023               0.048909       0.019094   \n",
       "201112031               0.069966       0.012547   \n",
       "201112033               0.048515       0.024953   \n",
       "201112035               0.048909       0.019094   \n",
       "201112053               0.050589       0.028603   \n",
       "201112055               0.048909       0.019094   \n",
       "201112057               0.043724       0.022451   \n",
       "201112061               0.042042       0.016952   \n",
       "201112069               0.050239       0.019444   \n",
       "201112071               0.048408       0.012875   \n",
       "201112073               0.025759       0.021014   \n",
       "201112081               0.043109       0.015695   \n",
       "201112083               0.056246       0.020798   \n",
       "201112085               0.033562       0.019286   \n",
       "201112086               0.073670       0.020923   \n",
       "201112087               0.048909       0.019094   \n",
       "201112089               0.048909       0.019094   \n",
       "201112091               0.053543       0.009514   \n",
       "201112095               0.054428       0.025545   \n",
       "201112097               0.071878       0.008725   \n",
       "201112099               0.047036       0.018859   \n",
       "201112101               0.055595       0.035595   \n",
       "...                          ...            ...   \n",
       "201654003               0.048391       0.038356   \n",
       "201654011               0.050540       0.017906   \n",
       "201654033               0.050671       0.008854   \n",
       "201654039               0.042872       0.029697   \n",
       "201654061               0.044547       0.007930   \n",
       "201654081               0.050540       0.017906   \n",
       "201654107               0.013842       0.015399   \n",
       "201655009               0.059434       0.013720   \n",
       "201655025               0.028759       0.027053   \n",
       "201655027               0.047324       0.012690   \n",
       "201655035               0.051113       0.012940   \n",
       "201655039               0.056220       0.019669   \n",
       "201655055               0.041942       0.011990   \n",
       "201655059               0.056785       0.010555   \n",
       "201655063               0.042912       0.032632   \n",
       "201655071               0.060837       0.008315   \n",
       "201655073               0.035602       0.006382   \n",
       "201655079               0.047110       0.017094   \n",
       "201655087               0.036342       0.008640   \n",
       "201655089               0.037420       0.012823   \n",
       "201655097               0.051065       0.008131   \n",
       "201655101               0.061490       0.013684   \n",
       "201655105               0.038247       0.026341   \n",
       "201655109               0.052042       0.023498   \n",
       "201655117               0.028649       0.010139   \n",
       "201655127               0.034615       0.011609   \n",
       "201655131               0.035803       0.015786   \n",
       "201655133               0.038018       0.014992   \n",
       "201655139               0.030078       0.022100   \n",
       "201655141               0.067083       0.013280   \n",
       "\n",
       "           finance_insurance_realestate_1  prof_scientific_waste_1  \\\n",
       "new_index                                                            \n",
       "201112001                        0.041948                 0.092094   \n",
       "201112005                        0.083460                 0.123060   \n",
       "201112009                        0.048351                 0.130818   \n",
       "201112011                        0.080922                 0.137408   \n",
       "201112015                        0.060985                 0.096501   \n",
       "201112017                        0.060985                 0.096501   \n",
       "201112019                        0.096042                 0.082912   \n",
       "201112021                        0.094925                 0.126875   \n",
       "201112023                        0.060985                 0.096501   \n",
       "201112031                        0.115629                 0.118658   \n",
       "201112033                        0.063205                 0.115216   \n",
       "201112035                        0.060985                 0.096501   \n",
       "201112053                        0.085846                 0.072137   \n",
       "201112055                        0.060985                 0.096501   \n",
       "201112057                        0.109034                 0.138945   \n",
       "201112061                        0.070198                 0.144775   \n",
       "201112069                        0.054286                 0.113005   \n",
       "201112071                        0.070106                 0.121182   \n",
       "201112073                        0.050753                 0.133168   \n",
       "201112081                        0.075986                 0.121624   \n",
       "201112083                        0.039926                 0.119440   \n",
       "201112085                        0.050814                 0.108000   \n",
       "201112086                        0.065411                 0.127202   \n",
       "201112087                        0.060985                 0.096501   \n",
       "201112089                        0.060985                 0.096501   \n",
       "201112091                        0.058215                 0.126904   \n",
       "201112095                        0.064456                 0.143201   \n",
       "201112097                        0.036986                 0.094908   \n",
       "201112099                        0.078415                 0.134880   \n",
       "201112101                        0.060207                 0.123644   \n",
       "...                                   ...                      ...   \n",
       "201654003                        0.055690                 0.086356   \n",
       "201654011                        0.060702                 0.100859   \n",
       "201654033                        0.037357                 0.065794   \n",
       "201654039                        0.065889                 0.100224   \n",
       "201654061                        0.046173                 0.109550   \n",
       "201654081                        0.060702                 0.100859   \n",
       "201654107                        0.040665                 0.051311   \n",
       "201655009                        0.073024                 0.084382   \n",
       "201655025                        0.082944                 0.137849   \n",
       "201655027                        0.044261                 0.058373   \n",
       "201655035                        0.059241                 0.069514   \n",
       "201655039                        0.046906                 0.049081   \n",
       "201655055                        0.055012                 0.072291   \n",
       "201655059                        0.040375                 0.085926   \n",
       "201655063                        0.053741                 0.071180   \n",
       "201655071                        0.044403                 0.038843   \n",
       "201655073                        0.090070                 0.067402   \n",
       "201655079                        0.061934                 0.106110   \n",
       "201655087                        0.066174                 0.090829   \n",
       "201655089                        0.064551                 0.108895   \n",
       "201655097                        0.121597                 0.056865   \n",
       "201655101                        0.053119                 0.086634   \n",
       "201655105                        0.041678                 0.066037   \n",
       "201655109                        0.069111                 0.108966   \n",
       "201655117                        0.067037                 0.053613   \n",
       "201655127                        0.037276                 0.083076   \n",
       "201655131                        0.062445                 0.080276   \n",
       "201655133                        0.082146                 0.110605   \n",
       "201655139                        0.059290                 0.080581   \n",
       "201655141                        0.068585                 0.055542   \n",
       "\n",
       "           edu_health_1  arts_recreation_1   other_1  public_admin_1  score  \n",
       "new_index                                                                    \n",
       "201112001      0.404855           0.130712  0.036648        0.050313      0  \n",
       "201112005      0.194700           0.133705  0.037080        0.069798      0  \n",
       "201112009      0.219768           0.101508  0.051668        0.076642      0  \n",
       "201112011      0.220093           0.109108  0.059448        0.043507     64  \n",
       "201112015      0.240508           0.093014  0.048994        0.053334     22  \n",
       "201112017      0.240508           0.093014  0.048994        0.053334     29  \n",
       "201112019      0.216756           0.103497  0.049308        0.065317      0  \n",
       "201112021      0.182843           0.141784  0.080933        0.026748    119  \n",
       "201112023      0.240508           0.093014  0.048994        0.053334      0  \n",
       "201112031      0.195105           0.115136  0.045048        0.056154     38  \n",
       "201112033      0.241946           0.114828  0.053456        0.061675     38  \n",
       "201112035      0.240508           0.093014  0.048994        0.053334      0  \n",
       "201112053      0.219346           0.066540  0.059686        0.066431    353  \n",
       "201112055      0.240508           0.093014  0.048994        0.053334      0  \n",
       "201112057      0.207753           0.104718  0.053864        0.039637     55  \n",
       "201112061      0.215667           0.122365  0.063622        0.052687      0  \n",
       "201112069      0.192990           0.182436  0.049240        0.051608      0  \n",
       "201112071      0.211394           0.127848  0.059035        0.044726     66  \n",
       "201112073      0.275768           0.108641  0.054397        0.126958      0  \n",
       "201112081      0.212962           0.086070  0.061855        0.051599     33  \n",
       "201112083      0.222281           0.122796  0.036892        0.037813     67  \n",
       "201112085      0.219986           0.118947  0.063189        0.042322      0  \n",
       "201112086      0.204518           0.110786  0.059482        0.037436     70  \n",
       "201112087      0.240508           0.093014  0.048994        0.053334      0  \n",
       "201112089      0.240508           0.093014  0.048994        0.053334     21  \n",
       "201112091      0.203587           0.134240  0.047375        0.124459      0  \n",
       "201112095      0.188444           0.189584  0.051298        0.029484     42  \n",
       "201112097      0.160155           0.273923  0.041458        0.040701      0  \n",
       "201112099      0.210093           0.119793  0.062776        0.042159     28  \n",
       "201112101      0.231692           0.105988  0.048633        0.035561    161  \n",
       "...                 ...                ...       ...             ...    ...  \n",
       "201654003      0.225832           0.082092  0.039622        0.084122      0  \n",
       "201654011      0.238304           0.097315  0.048328        0.049026      0  \n",
       "201654033      0.296526           0.085022  0.047601        0.115786      0  \n",
       "201654039      0.270667           0.100113  0.040842        0.112526      0  \n",
       "201654061      0.360388           0.121354  0.035513        0.059201      0  \n",
       "201654081      0.238304           0.097315  0.048328        0.049026      0  \n",
       "201654107      0.320483           0.099258  0.045223        0.089474      0  \n",
       "201655009      0.202846           0.093170  0.039007        0.020846      0  \n",
       "201655025      0.285833           0.090658  0.039668        0.044714      0  \n",
       "201655027      0.185140           0.063427  0.048549        0.030040      0  \n",
       "201655035      0.267207           0.079175  0.047544        0.033937      0  \n",
       "201655039      0.209634           0.063600  0.035435        0.045790      0  \n",
       "201655055      0.238870           0.077360  0.043771        0.026514      0  \n",
       "201655059      0.225782           0.084677  0.045349        0.048229      0  \n",
       "201655063      0.298961           0.108936  0.046355        0.032293      0  \n",
       "201655071      0.210480           0.062227  0.037088        0.020994      0  \n",
       "201655073      0.227370           0.071343  0.035559        0.027045      0  \n",
       "201655079      0.258274           0.097210  0.044666        0.035156      0  \n",
       "201655087      0.207668           0.079542  0.031116        0.027592      0  \n",
       "201655089      0.233125           0.077941  0.032854        0.033925      0  \n",
       "201655097      0.258078           0.072386  0.036948        0.027890      0  \n",
       "201655101      0.207000           0.076496  0.040780        0.032095      0  \n",
       "201655105      0.212013           0.071704  0.030623        0.029149      0  \n",
       "201655109      0.196570           0.070616  0.057046        0.037007      0  \n",
       "201655117      0.185135           0.076792  0.039122        0.025314      0  \n",
       "201655127      0.225702           0.106738  0.033728        0.025108      0  \n",
       "201655131      0.207379           0.075402  0.050286        0.037876      0  \n",
       "201655133      0.223792           0.076854  0.036258        0.027043     78  \n",
       "201655139      0.199925           0.090166  0.043299        0.024915      0  \n",
       "201655141      0.256396           0.064132  0.034595        0.043448      0  \n",
       "\n",
       "[2546 rows x 84 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "X_Y.drop(columns=['county'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "X_Y.drop(columns=['geo_id'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X_Y.iloc[:,0:81]\n",
    "y = X_Y.score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l = Lasso(alpha=1.0)\n",
    "clf_l.fit(X_train, y_train)\n",
    "\n",
    "clf_r = Ridge(alpha=1.0)\n",
    "clf_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.50461162e+02,  8.22022447e+02, -1.89370347e+01, -8.05635039e+02,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  4.08687802e+02, -1.84666187e+02, -1.27006814e+03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  1.79926673e+03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -3.83676640e+02, -0.00000000e+00,  5.19592907e+02, -0.00000000e+00,\n",
       "       -0.00000000e+00,  1.86304045e+03, -7.83946181e+00,  1.48458237e-03,\n",
       "        0.00000000e+00,  6.22726419e+02,  0.00000000e+00, -2.77577345e+03,\n",
       "       -3.99162610e+03, -0.00000000e+00, -0.00000000e+00, -1.24880465e+03,\n",
       "        0.00000000e+00, -0.00000000e+00,  8.12711704e+01, -0.00000000e+00,\n",
       "        1.02795334e+03,  4.74250133e+02,  3.27878875e+02,  3.04114997e+03,\n",
       "       -2.90043072e+02, -0.00000000e+00, -0.00000000e+00,  6.85233497e+02,\n",
       "       -1.09270930e+03, -0.00000000e+00, -0.00000000e+00, -3.10304561e+03,\n",
       "       -0.00000000e+00,  2.75376465e+03,  4.99273563e+02,  8.83300742e+02,\n",
       "       -2.82786961e+02,  8.11057101e+02, -3.59073719e+02,  0.00000000e+00,\n",
       "       -5.57747783e+02, -6.26164013e+02,  1.02748654e+03,  1.63414283e+02,\n",
       "       -4.45961389e+01, -0.00000000e+00, -0.00000000e+00, -3.96829207e+00,\n",
       "        3.33478623e+02,  2.41042527e+02, -7.74523647e+01,  4.52652857e+02,\n",
       "        0.00000000e+00, -5.39822320e+02, -4.77889699e+02,  0.00000000e+00,\n",
       "        1.38245312e+02, -3.49218355e+01, -3.04058811e+02,  5.92034382e+01,\n",
       "       -6.29346816e+02])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' :[0.001, 0.01, 0.02, 0.03,0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 1]}\n",
    "clf_l = GridSearchCV(cv=5, estimator = Lasso(), param_grid = params, scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.04}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.04, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l = Lasso(alpha = 0.04)\n",
    "clf_l.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mining_quarrying_oilgas_extract', 'total_prof_sci_mgmt_admin', 'mgmt',\n",
       "       'year', 'fips_1', 'agri_fish_hunt_1',\n",
       "       'mining_quarrying_oilgas_extract_1', 'construction_1',\n",
       "       'manufacturing_1', 'transport_warehouse_utilities_1', 'utilities_1',\n",
       "       'prof_sci_tech_1', 'mgmt_1', 'pub_admin_1', 'agriculture',\n",
       "       'construction', 'manufacturing', 'wholesale_trade', 'retail_trade',\n",
       "       'finance_insurance_realestate', 'prof_scientific_waste', 'edu_health',\n",
       "       'arts_recreation', 'other', 'public_admin', 'year', 'agriculture_1',\n",
       "       'construction_1', 'manufacturing_1', 'retail_trade_1',\n",
       "       'transport_utilities_1', 'finance_insurance_realestate_1',\n",
       "       'prof_scientific_waste_1', 'edu_health_1', 'public_admin_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[clf_l.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.argsort(abs(clf_l.coef_))\n",
    "sort_array = np.sort(abs(clf_l.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_array = sort_array[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sort_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Sorted Coefficient for different features (Uranium)')"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.bar(range(81), sort_array)\n",
    "\n",
    "plt.xlabel('Ranking of Features')\n",
    "plt.ylabel('abs(Coefficient) of LASSO')\n",
    "plt.title(r'Sorted Coefficient for different features (Uranium)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['manufacturing_1', 'pub_admin_1', 'prof_sci_tech_1', 'wholesale_trade',\n",
       "       'agri_fish_hunt_1', 'prof_scientific_waste', 'retail_trade',\n",
       "       'prof_scientific_waste_1', 'mgmt', 'retail_trade_1',\n",
       "       'transport_warehouse_utilities_1', 'construction_1', 'construction',\n",
       "       'agriculture', 'mining_quarrying_oilgas_extract', 'agriculture_1',\n",
       "       'finance_insurance_realestate_1', 'total_prof_sci_mgmt_admin',\n",
       "       'edu_health', 'edu_health_1', 'finance_insurance_realestate',\n",
       "       'manufacturing', 'mgmt_1', 'mining_quarrying_oilgas_extract_1',\n",
       "       'manufacturing_1', 'public_admin', 'other', 'arts_recreation',\n",
       "       'utilities_1', 'year', 'public_admin_1', 'transport_utilities_1',\n",
       "       'construction_1', 'year', 'fips_1', 'total_arts_ent_acc_food',\n",
       "       'health_social', 'edu_serv', 'admin_sup', 'total_edu_health_social',\n",
       "       'arts_ent_rec', 'retail_trade', 'prof_sci_tech', 'realest_rent_lease',\n",
       "       'fin_ins', 'fin_ins_realest', 'information', 'utilities',\n",
       "       'transport_warehouse', 'transport_warehouse_utilities', 'other_ser',\n",
       "       'wholesale_trade', 'manufacturing', 'construction', 'agri_fish_hunt',\n",
       "       'acc_food_serv', 'fin_ins_1', 'pub_admin', 'total_agri_fish_mine_1',\n",
       "       'arts_recreation_1', 'information_1', 'wholesale_trade_1',\n",
       "       'information', 'transport_utilities', 'other_ser_1', 'acc_food_serv_1',\n",
       "       'arts_ent_rec_1', 'total_arts_ent_acc_food_1', 'health_social_1',\n",
       "       'edu_serv_1', 'total_edu_health_social_1', 'admin_sup_1',\n",
       "       'total_prof_sci_mgmt_admin_1', 'realest_rent_lease_1', 'other_1',\n",
       "       'fin_ins_realest_1', 'information_1', 'transport_warehouse_1',\n",
       "       'retail_trade_1', 'wholesale_trade_1', 'total_agri_fish_mine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[index[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 53, 43, 57, 29, 62, 58, 76, 16, 72, 35, 69, 55, 54,  2, 68, 75,\n",
       "       14, 63, 77, 61, 56, 44, 30, 70, 66, 65, 64, 37, 26, 80, 73, 31, 67,\n",
       "       27, 21, 20, 19, 17, 18, 22,  6, 15, 13, 12, 11, 10,  9,  8,  7, 24,\n",
       "        5,  4,  3,  1, 23, 40, 25, 28, 78, 74, 71, 60, 59, 52, 51, 50, 49,\n",
       "       48, 47, 46, 45, 42, 41, 79, 39, 38, 36, 34, 33,  0])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3433.3136961927103"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.coef_[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905.4348243932236"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.coef_[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139419.92756517805"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_l.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52076.60334842034"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t_pred = clf_l.predict(X_train)\n",
    "mean_squared_error(y_train, y_t_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], 'alpha': [0.001, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "params = {'alpha' :[0.001, 0.01, 0.02, 0.03,0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1,0.2,1], 'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7]}\n",
    "clf_l = GridSearchCV(cv=5, estimator = ElasticNet(), param_grid = params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "clf_l.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'l1_ratio': 0.7}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'l1_ratio': 0.7}"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha' :[0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009], 'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7]}\n",
    "clf_l = GridSearchCV(cv=5, estimator = ElasticNet(), param_grid = params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "clf_l.fit(X, y)\n",
    "clf_l.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0, copy_X=True, fit_intercept=True, l1_ratio=0.6,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l = ElasticNet(alpha = 0, l1_ratio = 0.7)\n",
    "clf_l.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135456.10175321007"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_l.predict(X_test)\n",
    "\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51771.99043356526"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t_pred = clf_l.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_t_pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
